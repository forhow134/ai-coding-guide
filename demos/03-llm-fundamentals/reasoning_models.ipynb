{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 æ¨ç†æ¨¡å‹ vs å¸¸è§„æ¨¡å‹\n",
    "\n",
    "æœ¬ç¬”è®°æœ¬å°†å¯¹æ¯”æ¨ç†æ¨¡å‹(Reasoning Models)å’Œå¸¸è§„æ¨¡å‹çš„åŒºåˆ«,å¸®åŠ©ä½ äº†è§£ä½•æ—¶ä½¿ç”¨æ¨ç†æ¨¡å‹ã€‚\n",
    "\n",
    "æ¨ç†æ¨¡å‹(å¦‚ DeepSeek R1, OpenAI o1)ä¼šåœ¨ç”Ÿæˆç­”æ¡ˆå‰è¿›è¡Œâ€œæ€è€ƒâ€,æ“…é•¿å¤æ‚æ¨ç†ä»»åŠ¡ã€‚\n",
    "\n",
    "**é¢„ä¼°æˆæœ¬**: ~$0.05\n",
    "\n",
    "**å®‰è£…ä¾èµ–**:\n",
    "```bash\n",
    "pip install openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from typing import Dict, Any, Optional\n",
    "import time\n",
    "\n",
    "# Initializeå®¢æˆ·ç«¯\n",
    "openai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# DeepSeek API (å…¼å®¹ OpenAI æ ¼å¼)\n",
    "deepseek_client = OpenAI(\n",
    "    api_key=os.environ.get(\"DEEPSEEK_API_KEY\"),\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "# æ£€æŸ¥ API keys\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"âš ï¸  è­¦å‘Š: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡\")\n",
    "else:\n",
    "    print(\"âœ“ OpenAI API key å·²è®¾ç½®\")\n",
    "\n",
    "if not os.environ.get(\"DEEPSEEK_API_KEY\"):\n",
    "    print(\"âš ï¸  è­¦å‘Š: æœªè®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡\")\n",
    "    print(\"  å¯åœ¨ https://platform.deepseek.com/ å…è´¹è·å–\")\n",
    "else:\n",
    "    print(\"âœ“ DeepSeek API key å·²è®¾ç½®\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_regular_model(prompt: str, model: str = \"gpt-4o-mini\") -> Dict[str, Any]:\n",
    "    \"\"\"è°ƒç”¨å¸¸è§„æ¨¡å‹\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0  # ä½¿ç”¨ç¡®å®šæ€§è¾“å‡ºä»¥ä¾¿æ¯”è¾ƒ\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"content\": response.choices[0].message.content,\n",
    "        \"reasoning\": None,  # å¸¸è§„æ¨¡å‹æ²¡æœ‰æ¨ç†è¿‡ç¨‹\n",
    "        \"usage\": {\n",
    "            \"prompt_tokens\": response.usage.prompt_tokens,\n",
    "            \"completion_tokens\": response.usage.completion_tokens,\n",
    "            \"total_tokens\": response.usage.total_tokens\n",
    "        },\n",
    "        \"time_seconds\": elapsed\n",
    "    }\n",
    "\n",
    "def call_reasoning_model(prompt: str, model: str = \"deepseek-reasoner\") -> Dict[str, Any]:\n",
    "    \"\"\"è°ƒç”¨æ¨ç†æ¨¡å‹ (DeepSeek R1)\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = deepseek_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # DeepSeek R1 åœ¨ reasoning_content å­—æ®µè¿”å›æ€è€ƒè¿‡ç¨‹\n",
    "    reasoning = None\n",
    "    if hasattr(response.choices[0].message, 'reasoning_content'):\n",
    "        reasoning = response.choices[0].message.reasoning_content\n",
    "    \n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"content\": response.choices[0].message.content,\n",
    "        \"reasoning\": reasoning,\n",
    "        \"usage\": {\n",
    "            \"prompt_tokens\": response.usage.prompt_tokens,\n",
    "            \"completion_tokens\": response.usage.completion_tokens,\n",
    "            \"total_tokens\": response.usage.total_tokens\n",
    "        },\n",
    "        \"time_seconds\": elapsed\n",
    "    }\n",
    "\n",
    "def compare_models(prompt: str, description: str = \"\"):\n",
    "    \"\"\"å¯¹æ¯”å¸¸è§„æ¨¡å‹å’Œæ¨ç†æ¨¡å‹\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    if description:\n",
    "        print(f\"æµ‹è¯•åœºæ™¯: {description}\")\n",
    "    print(f\"\\næç¤ºè¯: {prompt}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Testå¸¸è§„æ¨¡å‹\n",
    "    print(\"\\nğŸ¤– å¸¸è§„æ¨¡å‹ (GPT-4o-mini)\")\n",
    "    print(\"-\" * 80)\n",
    "    try:\n",
    "        regular_result = call_regular_model(prompt)\n",
    "        print(f\"\\n{regular_result['content']}\")\n",
    "        print(f\"\\nğŸ“Š Tokens: {regular_result['usage']['total_tokens']} | \"\n",
    "              f\"æ—¶é—´: {regular_result['time_seconds']:.2f}s\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯: {e}\")\n",
    "        regular_result = None\n",
    "    \n",
    "    # Testæ¨ç†æ¨¡å‹\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"\\nğŸ§  æ¨ç†æ¨¡å‹ (DeepSeek R1)\")\n",
    "    print(\"-\" * 80)\n",
    "    try:\n",
    "        reasoning_result = call_reasoning_model(prompt)\n",
    "        \n",
    "        # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹(å¦‚æœæœ‰)\n",
    "        if reasoning_result['reasoning']:\n",
    "            print(\"\\nğŸ’­ æ€è€ƒè¿‡ç¨‹:\")\n",
    "            # åªæ˜¾ç¤ºå‰500å­—ç¬¦,é¿å…è¿‡é•¿\n",
    "            reasoning_preview = reasoning_result['reasoning'][:500]\n",
    "            print(f\"{reasoning_preview}...\" if len(reasoning_result['reasoning']) > 500 \n",
    "                  else reasoning_result['reasoning'])\n",
    "            print(f\"\\n[å®Œæ•´æ€è€ƒè¿‡ç¨‹: {len(reasoning_result['reasoning'])} å­—ç¬¦]\")\n",
    "        \n",
    "        print(\"\\nâœ… æœ€ç»ˆç­”æ¡ˆ:\")\n",
    "        print(f\"{reasoning_result['content']}\")\n",
    "        print(f\"\\nğŸ“Š Tokens: {reasoning_result['usage']['total_tokens']} | \"\n",
    "              f\"æ—¶é—´: {reasoning_result['time_seconds']:.2f}s\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯: {e}\")\n",
    "        reasoning_result = None\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    return regular_result, reasoning_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1: æ•°å­¦æ¨ç†é—®é¢˜\n",
    "\n",
    "æ¨ç†æ¨¡å‹åœ¨å¤šæ­¥éª¤æ•°å­¦é—®é¢˜ä¸Šè¡¨ç°æ›´å¥½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_problem = \"\"\"\n",
    "å°æ˜æœ‰ 100 å…ƒ,ä»–ä¹°äº† 3 æœ¬ä¹¦,æ¯æœ¬ 15 å…ƒã€‚\n",
    "ç„¶åä»–ç”¨å‰©ä½™é’±çš„ä¸€åŠä¹°äº†é›¶é£Ÿã€‚\n",
    "ä¹‹åä»–åˆèµšäº† 20 å…ƒã€‚\n",
    "æœ€åä»–ä¹°äº†ä¸€ä¸ª 30 å…ƒçš„ç©å…·ã€‚\n",
    "\n",
    "è¯·é—®å°æ˜ç°åœ¨è¿˜å‰©å¤šå°‘é’±?\n",
    "è¯·è¯¦ç»†åˆ—å‡ºè®¡ç®—æ­¥éª¤ã€‚\n",
    "\"\"\"\n",
    "\n",
    "compare_models(math_problem, \"å¤šæ­¥éª¤æ•°å­¦è®¡ç®—\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 2: æŸ¥çœ‹æ¨ç†Modelsçš„æ€è€ƒè¿‡ç¨‹\n",
    "<!-- Demo 2: æŸ¥çœ‹æ¨ç†æ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹ -->\n",
    "\n",
    "æ¨ç†æ¨¡å‹çš„ç‹¬ç‰¹ä¹‹å¤„åœ¨äºå®ƒä¼šæš´éœ²â€œæ€è€ƒâ€è¿‡ç¨‹,è®©æˆ‘ä»¬çœ‹çœ‹å®ƒå¦‚ä½•åˆ†æé—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_problem = \"\"\"\n",
    "æœ‰ä¸‰ä¸ªå¼€å…³å’Œä¸‰ç›ç¯,å¼€å…³åœ¨æ¥¼ä¸‹,ç¯åœ¨æ¥¼ä¸Šã€‚\n",
    "ä½ åªèƒ½ä¸Šæ¥¼ä¸€æ¬¡,å¦‚ä½•ç¡®å®šå“ªä¸ªå¼€å…³æ§åˆ¶å“ªç›ç¯?\n",
    "\"\"\"\n",
    "\n",
    "print(\"æŸ¥çœ‹æ¨ç†æ¨¡å‹çš„å®Œæ•´æ€è€ƒè¿‡ç¨‹\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"é—®é¢˜: {reasoning_problem}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    result = call_reasoning_model(reasoning_problem)\n",
    "    \n",
    "    if result['reasoning']:\n",
    "        print(\"\\nğŸ§  å®Œæ•´æ€è€ƒè¿‡ç¨‹:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(result['reasoning'])\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"\\næ€è€ƒè¿‡ç¨‹é•¿åº¦: {len(result['reasoning'])} å­—ç¬¦\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"\\nâœ… æœ€ç»ˆç­”æ¡ˆ:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(result['content'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"\\nğŸ’¡ è§‚å¯Ÿ:\")\n",
    "    print(\"- æ¨ç†æ¨¡å‹ä¼šå…ˆåˆ†æé—®é¢˜,è€ƒè™‘å¤šç§å¯èƒ½æ€§\")\n",
    "    print(\"- æ€è€ƒè¿‡ç¨‹å±•ç¤ºäº†é—®é¢˜åˆ†è§£å’Œé€»è¾‘æ¨æ¼”\")\n",
    "    print(\"- æœ€ç»ˆç­”æ¡ˆæ›´æœ‰æ¡ç†å’Œä¾æ®\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ é”™è¯¯: {e}\")\n",
    "    print(\"\\næç¤º: ç¡®ä¿å·²è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 3: é€»è¾‘è°œé¢˜Comparison\n",
    "<!-- Demo 3: é€»è¾‘è°œé¢˜å¯¹æ¯” -->\n",
    "\n",
    "æµ‹è¯•ä¸€ä¸ªéœ€è¦å¤æ‚é€»è¾‘æ¨ç†çš„è°œé¢˜,çœ‹å¸¸è§„æ¨¡å‹å’Œæ¨ç†æ¨¡å‹çš„è¡¨ç°å·®å¼‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_puzzle = \"\"\"\n",
    "æœ‰ä¸‰ä¸ªäºº:Aã€Bã€Cã€‚\n",
    "- A è¯´:â€œB åœ¨è¯´è°ã€‚â€\n",
    "- B è¯´:â€œC åœ¨è¯´è°ã€‚â€\n",
    "- C è¯´:â€œA å’Œ B éƒ½åœ¨è¯´è°ã€‚â€\n",
    "\n",
    "å·²çŸ¥è¿™ä¸‰ä¸ªäººä¸­åªæœ‰ä¸€ä¸ªäººè¯´çš„æ˜¯çœŸè¯ã€‚\n",
    "è¯·é—®è°è¯´çš„æ˜¯çœŸè¯?è¯·ç»™å‡ºè¯¦ç»†æ¨ç†è¿‡ç¨‹ã€‚\n",
    "\"\"\"\n",
    "\n",
    "regular_result, reasoning_result = compare_models(logic_puzzle, \"é€»è¾‘è°œé¢˜\")\n",
    "\n",
    "print(\"\\nğŸ“ å¯¹æ¯”åˆ†æ:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if regular_result and reasoning_result:\n",
    "    print(\"\\nå¸¸è§„æ¨¡å‹:\")\n",
    "    print(f\"  - Token ä½¿ç”¨: {regular_result['usage']['total_tokens']}\")\n",
    "    print(f\"  - å“åº”æ—¶é—´: {regular_result['time_seconds']:.2f}s\")\n",
    "    print(f\"  - æ¨ç†è¿‡ç¨‹: ä¸å¯è§\")\n",
    "    \n",
    "    print(\"\\næ¨ç†æ¨¡å‹:\")\n",
    "    print(f\"  - Token ä½¿ç”¨: {reasoning_result['usage']['total_tokens']}\")\n",
    "    print(f\"  - å“åº”æ—¶é—´: {reasoning_result['time_seconds']:.2f}s\")\n",
    "    has_reasoning = reasoning_result['reasoning'] is not None\n",
    "    print(f\"  - æ¨ç†è¿‡ç¨‹: {'å¯è§ (' + str(len(reasoning_result['reasoning'])) + ' å­—ç¬¦)' if has_reasoning else 'ä¸å¯è§'}\")\n",
    "    \n",
    "    if reasoning_result['usage']['total_tokens'] > regular_result['usage']['total_tokens']:\n",
    "        ratio = reasoning_result['usage']['total_tokens'] / regular_result['usage']['total_tokens']\n",
    "        print(f\"\\næ¨ç†æ¨¡å‹ä½¿ç”¨äº† {ratio:.1f}x çš„ tokens (å› ä¸ºåŒ…å«æ€è€ƒè¿‡ç¨‹)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 4: ä½•æ—¶ä¸åº”è¯¥ä½¿ç”¨æ¨ç†Models\n",
    "<!-- Demo 4: ä½•æ—¶ä¸åº”è¯¥ä½¿ç”¨æ¨ç†æ¨¡å‹ -->\n",
    "\n",
    "æ¨ç†æ¨¡å‹æ›´æ…¢ã€æ›´è´µ,å¯¹ç®€å•ä»»åŠ¡æ˜¯è¿‡åº¦è®¾è®¡ã€‚è®©æˆ‘ä»¬æµ‹è¯•å‡ ä¸ªç®€å•ä»»åŠ¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_tasks = [\n",
    "    {\n",
    "        \"task\": \"ç®€å•ç¿»è¯‘\",\n",
    "        \"prompt\": \"å°†ä»¥ä¸‹è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡: Hello, how are you today?\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"åŸºç¡€åˆ†ç±»\",\n",
    "        \"prompt\": \"åˆ¤æ–­ä»¥ä¸‹è¯„è®ºçš„æƒ…æ„Ÿ(æ­£é¢/è´Ÿé¢/ä¸­æ€§): è¿™ä¸ªäº§å“è¿˜ä¸é”™,ä½†ä»·æ ¼æœ‰ç‚¹è´µã€‚\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"ç®€å•æå–\",\n",
    "        \"prompt\": \"ä»ä»¥ä¸‹å¥å­æå–äººå: æé›·å’ŒéŸ©æ¢…æ¢…æ˜¯å¥½æœ‹å‹ã€‚\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"æ¨ç†æ¨¡å‹çš„ä¸é€‚ç”¨åœºæ™¯\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for task_info in simple_tasks:\n",
    "    print(f\"\\nä»»åŠ¡ç±»å‹: {task_info['task']}\")\n",
    "    print(f\"æç¤ºè¯: {task_info['prompt']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # å¸¸è§„æ¨¡å‹\n",
    "    try:\n",
    "        regular = call_regular_model(task_info['prompt'])\n",
    "        print(f\"\\nå¸¸è§„æ¨¡å‹: {regular['content'][:100]}\")\n",
    "        print(f\"  âš¡ {regular['time_seconds']:.2f}s | {regular['usage']['total_tokens']} tokens\")\n",
    "    except Exception as e:\n",
    "        print(f\"å¸¸è§„æ¨¡å‹é”™è¯¯: {e}\")\n",
    "        regular = None\n",
    "    \n",
    "    # æ¨ç†æ¨¡å‹\n",
    "    try:\n",
    "        reasoning = call_reasoning_model(task_info['prompt'])\n",
    "        print(f\"\\næ¨ç†æ¨¡å‹: {reasoning['content'][:100]}\")\n",
    "        print(f\"  ğŸŒ {reasoning['time_seconds']:.2f}s | {reasoning['usage']['total_tokens']} tokens\")\n",
    "    except Exception as e:\n",
    "        print(f\"æ¨ç†æ¨¡å‹é”™è¯¯: {e}\")\n",
    "        reasoning = None\n",
    "    \n",
    "    if regular and reasoning:\n",
    "        time_ratio = reasoning['time_seconds'] / regular['time_seconds']\n",
    "        token_ratio = reasoning['usage']['total_tokens'] / regular['usage']['total_tokens']\n",
    "        print(f\"\\n  ğŸ“Š æ¨ç†æ¨¡å‹ vs å¸¸è§„æ¨¡å‹:\")\n",
    "        print(f\"     - æ—¶é—´: {time_ratio:.1f}x æ›´æ…¢\")\n",
    "        print(f\"     - Tokens: {token_ratio:.1f}x æ›´å¤š\")\n",
    "        print(f\"     - ä»·å€¼: å¯¹äºç®€å•ä»»åŠ¡,é¢å¤–æˆæœ¬å’Œæ—¶é—´ä¸å€¼å¾—\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ’¡ ç»“è®º:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"å¯¹äºç®€å•ã€ç›´æ¥çš„ä»»åŠ¡(ç¿»è¯‘ã€åˆ†ç±»ã€æå–),å¸¸è§„æ¨¡å‹:\")\n",
    "print(\"  âœ“ å“åº”æ›´å¿«\")\n",
    "print(\"  âœ“ æˆæœ¬æ›´ä½\")\n",
    "print(\"  âœ“ è¾“å‡ºè´¨é‡è¶³å¤Ÿå¥½\")\n",
    "print(\"\\nåªåœ¨çœŸæ­£éœ€è¦å¤æ‚æ¨ç†æ—¶æ‰ä½¿ç”¨æ¨ç†æ¨¡å‹!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¨ç†Modelsä½¿ç”¨æŒ‡å—\n",
    "<!-- æ¨ç†æ¨¡å‹ä½¿ç”¨æŒ‡å— -->\n",
    "\n",
    "æ€»ç»“ä½•æ—¶åº”è¯¥(å’Œä¸åº”è¯¥)ä½¿ç”¨æ¨ç†æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Createå¯¹æ¯”è¡¨\n",
    "comparison_table = pd.DataFrame([\n",
    "    {\n",
    "        \"ä»»åŠ¡ç±»å‹\": \"å¤šæ­¥æ•°å­¦é—®é¢˜\",\n",
    "        \"æ¨èæ¨¡å‹\": \"æ¨ç†æ¨¡å‹\",\n",
    "        \"åŸå› \": \"éœ€è¦è®¡åˆ’å’ŒéªŒè¯è®¡ç®—æ­¥éª¤\",\n",
    "        \"ç¤ºä¾‹\": \"å¤æ‚çš„åº”ç”¨é¢˜ã€å¤šæ­¥è®¡ç®—\"\n",
    "    },\n",
    "    {\n",
    "        \"ä»»åŠ¡ç±»å‹\": \"é€»è¾‘è°œé¢˜\",\n",
    "        \"æ¨èæ¨¡å‹\": \"æ¨ç†æ¨¡å‹\",\n",
    "        \"åŸå› \": \"éœ€è¦å‡è®¾ã€æ¨æ¼”å’ŒéªŒè¯\",\n",
    "        \"ç¤ºä¾‹\": \"æ•°ç‹¬ã€é€»è¾‘æ¨ç†é¢˜\"\n",
    "    },\n",
    "    {\n",
    "        \"ä»»åŠ¡ç±»å‹\": \"ä»£ç è°ƒè¯•\",\n",
    "        \"æ¨èæ¨¡å‹\": \"æ¨ç†æ¨¡å‹\",\n",
    "        \"åŸå› \": \"éœ€è¦åˆ†æå› æœå…³ç³»\",\n",
    "        \"ç¤ºä¾‹\": \"å¤æ‚ bug åˆ†æã€ç®—æ³•ä¼˜åŒ–\"\n",
    "    },\n",
    "    {\n",
    "        \"ä»»åŠ¡ç±»å‹\": \"ç­–ç•¥è§„åˆ’\",\n",
    "        \"æ¨èæ¨¡å‹\": \"æ¨ç†æ¨¡å‹\",\n",
    "        \"åŸå› \": \"éœ€è¦æƒè¡¡åˆ©å¼Šã€è€ƒè™‘å¤šç§æ–¹æ¡ˆ\",\n",
    "        \"ç¤ºä¾‹\": \"ç³»ç»Ÿæ¶æ„è®¾è®¡ã€ä¸šåŠ¡å†³ç­–\"\n",
    "    },\n",
    "    {\n",
    "        \"ä»»åŠ¡ç±»å‹\": \"ç§‘å­¦æ¨ç†\",\n",
    "        \"æ¨èæ¨¡å‹\": \"æ¨ç†æ¨¡å‹\",\n",
    "        \"åŸå› \": \"éœ€è¦åŸºäºè¯æ®å¾—å‡ºç»“è®º\",\n",
    "        \"ç¤ºä¾‹\": \"å®éªŒåˆ†æã€å› æœæ¨æ–­\"\n",
    "    },\n",
    "    {\n",
    "        \"ä»»åŠ¡ç±»å‹\": \"ç®€å•ç¿»è¯‘\",\n",
    "        \"æ¨èæ¨¡å‹\": \"å¸¸è§„æ¨¡å‹\",\n",
    "        \"åŸå› \": \"ç›´æ¥æ˜ å°„,æ— éœ€æ¨ç†\",\n",
    "        \"ç¤ºä¾‹\": \"æ–‡æœ¬ç¿»è¯‘ã€æ ¼å¼è½¬æ¢\"\n",
    "    },\n",
    "    {\n",
    "        \"ä»»åŠ¡ç±»å‹\": \"æƒ…æ„Ÿåˆ†ç±»\",\n",
    "        \"æ¨èæ¨¡å‹\": \"å¸¸è§„æ¨¡å‹\",\n",
    "        \"åŸå› \": \"æ¨¡å¼è¯†åˆ«,ä¸éœ€è¦æ€è€ƒ\",\n",
    "        \"ç¤ºä¾‹\": \"è¯„è®ºåˆ†ç±»ã€æƒ…ç»ªæ£€æµ‹\"\n",
    "    },\n",
    "    {\n",
    "        \"ä»»åŠ¡ç±»å‹\": \"ä¿¡æ¯æå–\",\n",
    "        \"æ¨èæ¨¡å‹\": \"å¸¸è§„æ¨¡å‹\",\n",
    "        \"åŸå› \": \"ç»“æ„åŒ–æå–,æ— éœ€æ¨ç†\",\n",
    "        \"ç¤ºä¾‹\": \"å®ä½“è¯†åˆ«ã€å…³é”®è¯æå–\"\n",
    "    },\n",
    "    {\n",
    "        \"ä»»åŠ¡ç±»å‹\": \"æ–‡æœ¬æ”¹å†™\",\n",
    "        \"æ¨èæ¨¡å‹\": \"å¸¸è§„æ¨¡å‹\",\n",
    "        \"åŸå› \": \"è¯­è¨€è½¬æ¢,ä¸éœ€è¦åˆ†æ\",\n",
    "        \"ç¤ºä¾‹\": \"æ¶¦è‰²ã€ç¼©å†™ã€æ‰©å†™\"\n",
    "    },\n",
    "    {\n",
    "        \"ä»»åŠ¡ç±»å‹\": \"ç®€å•é—®ç­”\",\n",
    "        \"æ¨èæ¨¡å‹\": \"å¸¸è§„æ¨¡å‹\",\n",
    "        \"åŸå› \": \"äº‹å®æ£€ç´¢,æ— éœ€æ¨æ¼”\",\n",
    "        \"ç¤ºä¾‹\": \"å®šä¹‰è§£é‡Šã€åŸºç¡€çŸ¥è¯†\"\n",
    "    },\n",
    "])\n",
    "\n",
    "print(\"\\næ¨ç†æ¨¡å‹ vs å¸¸è§„æ¨¡å‹ä½¿ç”¨æŒ‡å—\\n\")\n",
    "print(comparison_table.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"\\nğŸ¯ å†³ç­–æµç¨‹:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\"\"\n",
    "1. é—®è‡ªå·±:è¿™ä¸ªä»»åŠ¡éœ€è¦â€œæ€è€ƒâ€å—?\n",
    "   - éœ€è¦å¤šæ­¥æ¨ç†? â†’ æ¨ç†æ¨¡å‹\n",
    "   - éœ€è¦æƒè¡¡é€‰é¡¹? â†’ æ¨ç†æ¨¡å‹\n",
    "   - éœ€è¦éªŒè¯ç­”æ¡ˆ? â†’ æ¨ç†æ¨¡å‹\n",
    "   - åªæ˜¯ç®€å•è½¬æ¢? â†’ å¸¸è§„æ¨¡å‹\n",
    "\n",
    "2. è€ƒè™‘æˆæœ¬å’Œæ—¶é—´:\n",
    "   - æ¨ç†æ¨¡å‹é€šå¸¸ 2-5x æ›´æ…¢\n",
    "   - æ¨ç†æ¨¡å‹é€šå¸¸ 2-10x æ›´è´µ(å› ä¸ºæ€è€ƒ tokens)\n",
    "   - ç¡®ä¿é¢å¤–æˆæœ¬ç‰©æœ‰æ‰€å€¼\n",
    "\n",
    "3. å…ˆç”¨å¸¸è§„æ¨¡å‹æµ‹è¯•:\n",
    "   - å¦‚æœå¸¸è§„æ¨¡å‹è¡¨ç°å¥½,å°±ä¸éœ€è¦æ¨ç†æ¨¡å‹\n",
    "   - åªåœ¨å¸¸è§„æ¨¡å‹å¤±è´¥æˆ–ä¸å¤Ÿå‡†ç¡®æ—¶å‡çº§\n",
    "\n",
    "4. ç›‘æ§æ•ˆæœ:\n",
    "   - è®°å½•å‡†ç¡®ç‡æå‡\n",
    "   - è®¡ç®—æˆæœ¬æ”¶ç›Šæ¯”\n",
    "   - å†³å®šæ˜¯å¦å€¼å¾—é•¿æœŸä½¿ç”¨æ¨ç†æ¨¡å‹\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nğŸ’° æˆæœ¬å¯¹æ¯”(2026å¹´2æœˆä¼°ç®—):\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\"\"\n",
    "å¸¸è§„æ¨¡å‹ (GPT-4o-mini):\n",
    "  - è¾“å…¥: $0.15 / 1M tokens\n",
    "  - è¾“å‡º: $0.60 / 1M tokens\n",
    "  - é€Ÿåº¦: å¿« (~1-2s)\n",
    "\n",
    "æ¨ç†æ¨¡å‹ (DeepSeek R1):\n",
    "  - è¾“å…¥: $0.55 / 1M tokens\n",
    "  - è¾“å‡º: $2.19 / 1M tokens\n",
    "  - ç¼“å­˜è¾“å‡º: $1.09 / 1M tokens\n",
    "  - é€Ÿåº¦: è¾ƒæ…¢ (~3-10s)\n",
    "  - æ³¨æ„: æ€è€ƒè¿‡ç¨‹ä¹Ÿè®¡å…¥ token æ•°!\n",
    "\n",
    "OpenAI o1 ç³»åˆ—:\n",
    "  - æ›´å¼ºä½†æ›´è´µ\n",
    "  - é€‚åˆæœ€å¤æ‚çš„æ¨ç†ä»»åŠ¡\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹ : æ‰¾ä¸€ä¸ªé€‚åˆæ¨ç†Modelsçš„é—®é¢˜\n",
    "<!-- ç»ƒä¹ : æ‰¾ä¸€ä¸ªé€‚åˆæ¨ç†æ¨¡å‹çš„é—®é¢˜ -->\n",
    "\n",
    "æ€è€ƒä½ å·¥ä½œä¸­é‡åˆ°çš„é—®é¢˜,å“ªäº›å¯ä»¥ä»æ¨ç†æ¨¡å‹ä¸­å—ç›Š?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨è¿™é‡Œè¾“å…¥ä½ çš„é—®é¢˜\n",
    "your_problem = \"\"\"\n",
    "åœ¨è¿™é‡Œæè¿°ä¸€ä¸ªä½ å·¥ä½œä¸­é‡åˆ°çš„å¤æ‚é—®é¢˜...\n",
    "\n",
    "ä¾‹å¦‚:\n",
    "- éœ€è¦å¤šæ­¥éª¤åˆ†æçš„æŠ€æœ¯å†³ç­–\n",
    "- éœ€è¦æƒè¡¡å¤šä¸ªå› ç´ çš„æ¶æ„é€‰æ‹©\n",
    "- å¤æ‚çš„æ•°æ®åˆ†ææˆ–æ¨ç†ä»»åŠ¡\n",
    "- éœ€è¦å‘ç°éšè—æ¨¡å¼æˆ–å› æœå…³ç³»çš„é—®é¢˜\n",
    "\"\"\"\n",
    "\n",
    "if your_problem.strip() and \"åœ¨è¿™é‡Œæè¿°\" not in your_problem:\n",
    "    print(\"åˆ†æä½ çš„é—®é¢˜...\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ç”¨å¸¸è§„æ¨¡å‹åˆ†æè¿™ä¸ªé—®é¢˜æ˜¯å¦é€‚åˆæ¨ç†æ¨¡å‹\n",
    "    analysis_prompt = f\"\"\"\n",
    "åˆ†æä»¥ä¸‹é—®é¢˜æ˜¯å¦é€‚åˆä½¿ç”¨æ¨ç†æ¨¡å‹(å¦‚ DeepSeek R1, OpenAI o1):\n",
    "\n",
    "{your_problem}\n",
    "\n",
    "è¯·è¯„ä¼°:\n",
    "1. è¿™ä¸ªé—®é¢˜æ˜¯å¦éœ€è¦å¤šæ­¥æ¨ç†?\n",
    "2. æ˜¯å¦éœ€è¦æƒè¡¡å¤šä¸ªé€‰é¡¹?\n",
    "3. æ˜¯å¦éœ€è¦å‘ç°éšè—çš„å› æœå…³ç³»?\n",
    "4. å¸¸è§„æ¨¡å‹å¯èƒ½åœ¨å“ªé‡Œå¤±è´¥?\n",
    "5. æ¨ç†æ¨¡å‹èƒ½å¸¦æ¥ä»€ä¹ˆä»·å€¼?\n",
    "\n",
    "æœ€åç»™å‡ºæ˜ç¡®å»ºè®®:é€‚åˆ/ä¸é€‚åˆæ¨ç†æ¨¡å‹,ä»¥åŠç†ç”±ã€‚\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        analysis = call_regular_model(analysis_prompt, model=\"gpt-4o-mini\")\n",
    "        print(\"ğŸ“Š é€‚ç”¨æ€§åˆ†æ:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(analysis['content'])\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        \n",
    "        # å¦‚æœåˆ¤æ–­é€‚åˆ,å¯ä»¥å°è¯•ç”¨æ¨ç†æ¨¡å‹è§£å†³\n",
    "        print(\"\\nè¦ç”¨æ¨ç†æ¨¡å‹å°è¯•è§£å†³è¿™ä¸ªé—®é¢˜å—? (y/n)\")\n",
    "        print(\"æç¤º: å–æ¶ˆæ³¨é‡Šä¸‹é¢çš„ä»£ç å¹¶è¿è¡Œ\")\n",
    "        \n",
    "        # # å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥è¿è¡Œ\n",
    "        # try:\n",
    "        #     reasoning_solution = call_reasoning_model(your_problem)\n",
    "        #     print(\"\\nğŸ§  æ¨ç†æ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹:\")\n",
    "        #     if reasoning_solution['reasoning']:\n",
    "        #         print(reasoning_solution['reasoning'][:1000] + \"...\")\n",
    "        #     print(\"\\nâœ… æ¨ç†æ¨¡å‹çš„ç­”æ¡ˆ:\")\n",
    "        #     print(reasoning_solution['content'])\n",
    "        # except Exception as e:\n",
    "        #     print(f\"é”™è¯¯: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"åˆ†æå¤±è´¥: {e}\")\n",
    "else:\n",
    "    print(\"è¯·åœ¨ä¸Šé¢çš„ your_problem å˜é‡ä¸­è¾“å…¥ä½ çš„é—®é¢˜,ç„¶åé‡æ–°è¿è¡Œæ­¤å•å…ƒæ ¼ã€‚\")\n",
    "    print(\"\\nğŸ’¡ æç¤º: é€‰æ‹©ä¸€ä¸ªçœŸæ­£éœ€è¦'æ€è€ƒ'çš„å¤æ‚é—®é¢˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "é€šè¿‡æœ¬ç¬”è®°æœ¬çš„å®éªŒ,ä½ åº”è¯¥ç†è§£äº†:\n",
    "\n",
    "### 1. æ¨ç†æ¨¡å‹çš„ç‰¹ç‚¹\n",
    "\n",
    "**ä¼˜åŠ¿**:\n",
    "- åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°æ›´å¥½\n",
    "- å¯ä»¥å±•ç¤ºæ€è€ƒè¿‡ç¨‹,æé«˜å¯è§£é‡Šæ€§\n",
    "- èƒ½å¤Ÿè¿›è¡Œå¤šæ­¥éª¤çš„é€»è¾‘æ¨æ¼”å’ŒéªŒè¯\n",
    "- åœ¨æ•°å­¦ã€é€»è¾‘ã€ç­–ç•¥è§„åˆ’ç­‰ä»»åŠ¡ä¸Šæ›´å‡†ç¡®\n",
    "\n",
    "**åŠ£åŠ¿**:\n",
    "- å“åº”æ—¶é—´æ›´é•¿(2-5x)\n",
    "- Token æ¶ˆè€—æ›´å¤š(åŒ…å«æ€è€ƒè¿‡ç¨‹)\n",
    "- æˆæœ¬æ›´é«˜(2-10x)\n",
    "- å¯¹ç®€å•ä»»åŠ¡æ˜¯è¿‡åº¦è®¾è®¡\n",
    "\n",
    "### 2. ä½•æ—¶ä½¿ç”¨æ¨ç†æ¨¡å‹\n",
    "\n",
    "**é€‚åˆçš„åœºæ™¯**:\n",
    "- âœ“ å¤šæ­¥æ•°å­¦é—®é¢˜å’Œåº”ç”¨é¢˜\n",
    "- âœ“ é€»è¾‘è°œé¢˜å’Œæ¨ç†é¢˜\n",
    "- âœ“ å¤æ‚ä»£ç è°ƒè¯•å’Œç®—æ³•åˆ†æ\n",
    "- âœ“ éœ€è¦æƒè¡¡çš„ç­–ç•¥å†³ç­–\n",
    "- âœ“ ç§‘å­¦æ¨ç†å’Œå› æœåˆ†æ\n",
    "\n",
    "**ä¸é€‚åˆçš„åœºæ™¯**:\n",
    "- âœ— ç®€å•ç¿»è¯‘å’Œè½¬æ¢\n",
    "- âœ— æƒ…æ„Ÿåˆ†ç±»å’Œå®ä½“è¯†åˆ«\n",
    "- âœ— ç›´æ¥çš„ä¿¡æ¯æå–\n",
    "- âœ— åŸºç¡€é—®ç­”å’ŒçŸ¥è¯†æ£€ç´¢\n",
    "- âœ— æ–‡æœ¬æ¶¦è‰²å’Œæ”¹å†™\n",
    "\n",
    "### 3. æœ€ä½³å®è·µ\n",
    "\n",
    "1. **å…ˆç”¨å¸¸è§„æ¨¡å‹**: å¦‚æœå¸¸è§„æ¨¡å‹å¤Ÿç”¨,å°±ä¸éœ€è¦æ¨ç†æ¨¡å‹\n",
    "2. **è¯„ä¼°æˆæœ¬æ”¶ç›Š**: ç¡®ä¿é¢å¤–æˆæœ¬èƒ½å¸¦æ¥ç›¸åº”çš„ä»·å€¼æå‡\n",
    "3. **åˆ©ç”¨æ€è€ƒè¿‡ç¨‹**: æ¨ç†æ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹æœ¬èº«å°±æ˜¯æœ‰ä»·å€¼çš„è¾“å‡º\n",
    "4. **ç›‘æ§å‡†ç¡®ç‡**: é‡åŒ–æ¨ç†æ¨¡å‹å¸¦æ¥çš„æ”¹è¿›\n",
    "5. **æ··åˆä½¿ç”¨**: ç®€å•ä»»åŠ¡ç”¨å¸¸è§„æ¨¡å‹,å¤æ‚ä»»åŠ¡ç”¨æ¨ç†æ¨¡å‹\n",
    "\n",
    "### 4. å¯ç”¨çš„æ¨ç†æ¨¡å‹\n",
    "\n",
    "- **DeepSeek R1**: å¼€æº,æˆæœ¬è¾ƒä½,æ€§èƒ½å¼ºå¤§\n",
    "- **OpenAI o1**: æœ€å¼ºä½†æœ€è´µ,é€‚åˆæœ€å¤æ‚çš„ä»»åŠ¡\n",
    "- **OpenAI o1-mini**: o1 çš„è½»é‡ç‰ˆ,å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬\n",
    "\n",
    "è®°ä½:**æ¨ç†èƒ½åŠ›æ˜¯æœ‰ä»£ä»·çš„**,åªåœ¨çœŸæ­£éœ€è¦æ—¶ä½¿ç”¨!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}