{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Token 与分词可视化\n",
    "\n",
    "本笔记本将帮助你理解 LLM 的基本单位 —— Token，以及它如何影响 API 成本。\n",
    "\n",
    "**成本**: $0 (仅使用 tiktoken 库，无需 API 调用)\n",
    "\n",
    "**安装依赖**:\n",
    "```bash\n",
    "pip install tiktoken\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from typing import List\n",
    "\n",
    "def visualize_tokens(text: str, encoding_name: str = \"cl100k_base\") -> None:\n",
    "    \"\"\"可视化文本的分词结果\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    tokens = encoding.encode(text)\n",
    "    \n",
    "    print(f\"原文: {text}\")\n",
    "    print(f\"\\nToken 数量: {len(tokens)}\")\n",
    "    print(f\"\\nToken IDs: {tokens}\")\n",
    "    print(f\"\\n分词结果:\")\n",
    "    \n",
    "    for i, token_id in enumerate(tokens):\n",
    "        token_str = encoding.decode([token_id])\n",
    "        print(f\"  [{i}] ID={token_id:6d} → '{token_str}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1: 英文 vs 中文分词Comparison\n",
    "<!-- Demo 1: 英文 vs 中文分词对比 -->\n",
    "\n",
    "观察英文和中文在分词上的差异。通常，中文每个汉字会占用更多的 token。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 英文文本\n",
    "english_text = \"Hello, how are you today?\"\n",
    "print(\"=\" * 60)\n",
    "print(\"英文分词:\")\n",
    "print(\"=\" * 60)\n",
    "visualize_tokens(english_text)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# 中文文本(大致相同含义)\n",
    "chinese_text = \"你好,你今天怎么样?\"\n",
    "print(\"中文分词:\")\n",
    "print(\"=\" * 60)\n",
    "visualize_tokens(chinese_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 2: 计算相同句子的Cost差异\n",
    "<!-- Demo 2: 计算相同句子的成本差异 -->\n",
    "\n",
    "比较英文和中文版本相同含义句子的 token 数量和成本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_cost(text: str, encoding_name: str = \"cl100k_base\",\n",
    "                  input_price_per_1m: float = 2.50,\n",
    "                  output_price_per_1m: float = 10.00) -> dict:\n",
    "    \"\"\"估算 API 调用成本\n",
    "    \n",
    "    Args:\n",
    "        text: 输入文本\n",
    "        encoding_name: 编码器名称\n",
    "        input_price_per_1m: 每百万输入 token 的价格(美元)\n",
    "        output_price_per_1m: 每百万输出 token 的价格(美元)\n",
    "    \n",
    "    Returns:\n",
    "        包含 token 数量和成本的字典\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    token_count = len(encoding.encode(text))\n",
    "    \n",
    "    input_cost = (token_count / 1_000_000) * input_price_per_1m\n",
    "    output_cost = (token_count / 1_000_000) * output_price_per_1m\n",
    "    \n",
    "    return {\n",
    "        \"token_count\": token_count,\n",
    "        \"input_cost_usd\": input_cost,\n",
    "        \"output_cost_usd\": output_cost,\n",
    "        \"total_cost_usd\": input_cost + output_cost\n",
    "    }\n",
    "\n",
    "# 示例句子\n",
    "english_sentence = \"Artificial intelligence is transforming how we build software applications.\"\n",
    "chinese_sentence = \"人工智能正在改变我们构建软件应用程序的方式。\"\n",
    "\n",
    "print(\"GPT-4o 定价 (2026年2月):\")\n",
    "print(\"  输入: $2.50 / 1M tokens\")\n",
    "print(\"  输出: $10.00 / 1M tokens\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "en_cost = estimate_cost(english_sentence)\n",
    "print(f\"\\n英文: '{english_sentence}'\")\n",
    "print(f\"  Token 数量: {en_cost['token_count']}\")\n",
    "print(f\"  输入成本: ${en_cost['input_cost_usd']:.6f}\")\n",
    "print(f\"  输出成本: ${en_cost['output_cost_usd']:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "cn_cost = estimate_cost(chinese_sentence)\n",
    "print(f\"\\n中文: '{chinese_sentence}'\")\n",
    "print(f\"  Token 数量: {cn_cost['token_count']}\")\n",
    "print(f\"  输入成本: ${cn_cost['input_cost_usd']:.6f}\")\n",
    "print(f\"  输出成本: ${cn_cost['output_cost_usd']:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"\\n中文 Token 数量是英文的 {cn_cost['token_count'] / en_cost['token_count']:.2f} 倍\")\n",
    "print(f\"中文成本是英文的 {cn_cost['total_cost_usd'] / en_cost['total_cost_usd']:.2f} 倍\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 3: 不同 Tokenizer 编码Comparison\n",
    "<!-- Demo 3: 不同 Tokenizer 编码对比 -->\n",
    "\n",
    "不同的模型使用不同的 tokenizer:\n",
    "- **cl100k_base**: GPT-4, GPT-3.5-turbo\n",
    "- **o200k_base**: GPT-4o 系列(更高效,特别是对非英语文本)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"人工智能 (AI) 正在改变世界! Artificial Intelligence is transforming the world!\"\n",
    "\n",
    "encodings = [\n",
    "    (\"cl100k_base\", \"GPT-4, GPT-3.5-turbo\"),\n",
    "    (\"o200k_base\", \"GPT-4o 系列\")\n",
    "]\n",
    "\n",
    "print(f\"测试文本: '{test_text}'\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "for encoding_name, models in encodings:\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    tokens = encoding.encode(test_text)\n",
    "    token_count = len(tokens)\n",
    "    results.append((encoding_name, models, token_count))\n",
    "    \n",
    "    print(f\"\\n{encoding_name} ({models}):\")\n",
    "    print(f\"  Token 数量: {token_count}\")\n",
    "    print(f\"  Token IDs: {tokens[:10]}{'...' if len(tokens) > 10 else ''}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\n总结:\")\n",
    "baseline = results[0][2]\n",
    "for encoding_name, models, count in results:\n",
    "    efficiency = (1 - count/baseline) * 100 if count < baseline else 0\n",
    "    print(f\"  {encoding_name}: {count} tokens\", end=\"\")\n",
    "    if efficiency > 0:\n",
    "        print(f\" (节省 {efficiency:.1f}%)\")\n",
    "    else:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 4: 估算 API Cost\n",
    "<!-- Demo 4: 估算 API 成本 -->\n",
    "\n",
    "针对一段实际文本,估算使用不同模型的成本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一段技术文档示例\n",
    "document = \"\"\"\n",
    "大语言模型(Large Language Model, LLM)是一种基于深度学习的自然语言处理模型。\n",
    "它通过在海量文本数据上进行预训练,学习语言的统计规律和语义关系。\n",
    "GPT-4o 是 OpenAI 推出的多模态模型,支持文本、图像和音频输入。\n",
    "相比前代模型,GPT-4o 在处理速度和成本效率上都有显著提升。\n",
    "它特别优化了对中文、日文等非英语语言的支持,token 效率提升约 50%。\n",
    "\n",
    "在实际应用中,选择合适的模型需要权衡:\n",
    "1. 任务复杂度 - 简单任务可使用 GPT-3.5 或 GPT-4o-mini\n",
    "2. 成本预算 - GPT-4o-mini 比 GPT-4o 便宜约 10 倍\n",
    "3. 响应速度 - 较小模型通常响应更快\n",
    "4. 输出质量 - 复杂推理任务需要更强大的模型\n",
    "\"\"\"\n",
    "\n",
    "# 定义不同模型的定价(2026年2月,美元/百万tokens)\n",
    "models = [\n",
    "    (\"GPT-4o\", \"o200k_base\", 2.50, 10.00),\n",
    "    (\"GPT-4o-mini\", \"o200k_base\", 0.15, 0.60),\n",
    "    (\"GPT-4-turbo\", \"cl100k_base\", 10.00, 30.00),\n",
    "    (\"GPT-3.5-turbo\", \"cl100k_base\", 0.50, 1.50),\n",
    "]\n",
    "\n",
    "print(f\"文档长度: {len(document)} 字符\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'模型':<18} {'Token':<8} {'输入成本':<12} {'输出成本':<12} {'总成本':<12}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for model_name, encoding_name, input_price, output_price in models:\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    token_count = len(encoding.encode(document))\n",
    "    \n",
    "    input_cost = (token_count / 1_000_000) * input_price\n",
    "    output_cost = (token_count / 1_000_000) * output_price  # 假设输出与输入等长\n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    print(f\"{model_name:<18} {token_count:<8} ${input_cost:<11.6f} ${output_cost:<11.6f} ${total_cost:<11.6f}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n注: 以上成本假设输出长度与输入相同。实际成本取决于具体的输出长度。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 5: 上下文窗口限制\n",
    "\n",
    "每个模型都有最大 token 限制(上下文窗口)。超过限制会导致 API 调用失败。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_context_window(text: str, model: str, max_tokens: int, \n",
    "                         encoding_name: str = \"o200k_base\") -> dict:\n",
    "    \"\"\"检查文本是否超出模型的上下文窗口\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    token_count = len(encoding.encode(text))\n",
    "    \n",
    "    remaining = max_tokens - token_count\n",
    "    usage_percent = (token_count / max_tokens) * 100\n",
    "    \n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"token_count\": token_count,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"remaining\": remaining,\n",
    "        \"usage_percent\": usage_percent,\n",
    "        \"is_valid\": token_count <= max_tokens\n",
    "    }\n",
    "\n",
    "# Generate一段长文本\n",
    "long_text = \"这是一段测试文本。\" * 1000  # 重复1000次\n",
    "\n",
    "# 不同模型的上下文窗口限制\n",
    "model_limits = [\n",
    "    (\"GPT-4o\", 128000, \"o200k_base\"),\n",
    "    (\"GPT-4o-mini\", 128000, \"o200k_base\"),\n",
    "    (\"GPT-4-turbo\", 128000, \"cl100k_base\"),\n",
    "    (\"GPT-3.5-turbo\", 16385, \"cl100k_base\"),\n",
    "]\n",
    "\n",
    "print(f\"测试文本长度: {len(long_text)} 字符\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'模型':<18} {'Token 数':<12} {'上限':<12} {'剩余':<12} {'使用率':<12} {'状态'}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for model, max_tokens, encoding_name in model_limits:\n",
    "    result = check_context_window(long_text, model, max_tokens, encoding_name)\n",
    "    \n",
    "    status = \"✓ 可用\" if result[\"is_valid\"] else \"✗ 超限\"\n",
    "    print(f\"{result['model']:<18} \"\n",
    "          f\"{result['token_count']:<12} \"\n",
    "          f\"{result['max_tokens']:<12} \"\n",
    "          f\"{result['remaining']:<12} \"\n",
    "          f\"{result['usage_percent']:<11.1f}% \"\n",
    "          f\"{status}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n建议: 对于长文档处理,预留至少 20-30% 的空间用于系统提示和输出。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习: Analysis你自己的文本\n",
    "<!-- 练习: 分析你自己的文本 -->\n",
    "\n",
    "将你工作中的一段文本粘贴到下面,分析它的 token 数量和 API 成本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在这里粘贴你的文本\n",
    "your_text = \"\"\"\n",
    "在这里粘贴你想分析的文本...\n",
    "\"\"\"\n",
    "\n",
    "if your_text.strip() and your_text.strip() != \"在这里粘贴你想分析的文本...\":\n",
    "    print(\"文本分析结果:\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 分词可视化(只显示前20个token)\n",
    "    encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "    tokens = encoding.encode(your_text)\n",
    "    print(f\"总 Token 数: {len(tokens)}\\n\")\n",
    "    print(\"前 20 个 Tokens:\")\n",
    "    for i, token_id in enumerate(tokens[:20]):\n",
    "        token_str = encoding.decode([token_id])\n",
    "        print(f\"  [{i}] '{token_str}'\")\n",
    "    if len(tokens) > 20:\n",
    "        print(f\"  ... 还有 {len(tokens) - 20} 个 tokens\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"\\n成本估算 (假设输出与输入等长):\\n\")\n",
    "    \n",
    "    # 成本估算\n",
    "    models_for_estimate = [\n",
    "        (\"GPT-4o\", \"o200k_base\", 2.50, 10.00),\n",
    "        (\"GPT-4o-mini\", \"o200k_base\", 0.15, 0.60),\n",
    "    ]\n",
    "    \n",
    "    for model_name, encoding_name, input_price, output_price in models_for_estimate:\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        token_count = len(encoding.encode(your_text))\n",
    "        \n",
    "        input_cost = (token_count / 1_000_000) * input_price\n",
    "        output_cost = (token_count / 1_000_000) * output_price\n",
    "        total_cost = input_cost + output_cost\n",
    "        \n",
    "        print(f\"{model_name}:\")\n",
    "        print(f\"  Token 数: {token_count}\")\n",
    "        print(f\"  输入成本: ${input_cost:.6f}\")\n",
    "        print(f\"  输出成本: ${output_cost:.6f}\")\n",
    "        print(f\"  总成本: ${total_cost:.6f}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"请在上面的 your_text 变量中粘贴你的文本,然后重新运行此单元格。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "通过本笔记本,你应该了解到:\n",
    "\n",
    "1. **Token 是什么**: LLM 处理文本的基本单位,通常一个 token 约等于 4 个英文字符或 1.5 个中文字符\n",
    "\n",
    "2. **语言差异**: 中文通常比英文消耗更多 token,但 GPT-4o 的新 tokenizer (o200k_base) 显著改善了这一问题\n",
    "\n",
    "3. **成本计算**: API 成本直接与 token 数量相关,输入和输出分别计费\n",
    "\n",
    "4. **模型选择**: 根据任务复杂度和预算选择合适的模型\n",
    "\n",
    "5. **上下文限制**: 注意每个模型的最大 token 限制,为输出预留足够空间\n",
    "\n",
    "**最佳实践**:\n",
    "- 使用 tiktoken 在发送请求前预估成本\n",
    "- 对于中文应用,优先选择 GPT-4o 系列(使用 o200k_base tokenizer)\n",
    "- 简单任务使用 mini 模型节省成本\n",
    "- 监控 token 使用量,避免超出上下文窗口"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}