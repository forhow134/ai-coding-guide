{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.4 记忆聊天机器人\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/forhow134/ai-coding-guide/blob/main/demos/12-rag-memory/memory_chatbot.ipynb)\n",
    "\n",
    "**预计 API 费用: ~$0.02**\n",
    "\n",
    "本 Notebook 实现带记忆的聊天机器人。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: BasicsConversationMemory\n",
    "<!-- 实验 1: 基础对话记忆 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# Create记忆\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Create对话链\n",
    "conversation = ConversationChain(\n",
    "    llm=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 对话测试\n",
    "print(\"=== 对话 1 ===\")\n",
    "response1 = conversation.predict(input=\"我叫小明\")\n",
    "print(f\"AI: {response1}\")\n",
    "\n",
    "print(\"\\n=== 对话 2 ===\")\n",
    "response2 = conversation.predict(input=\"我 25 岁,喜欢编程\")\n",
    "print(f\"AI: {response2}\")\n",
    "\n",
    "print(\"\\n=== 对话 3 ===\")\n",
    "response3 = conversation.predict(input=\"我叫什么名字?多大年纪?\")\n",
    "print(f\"AI: {response3}\")\n",
    "\n",
    "# 查看记忆\n",
    "print(\"\\n=== 记忆内容 ===\")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: 窗口Memory\n",
    "<!-- 实验 2: 窗口记忆 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n\n# 只保留最近 3 轮对话\nmemory_window = ConversationBufferWindowMemory(k=3)\nconversation_window = ConversationChain(\n    llm=ChatOpenAI(model=\"gpt-4o-mini\"),\n    memory=memory_window\n)\n\nconversations = [\n    \"我叫小明\",\n    \"我 25 岁\",\n    \"我在北京\",\n    \"我喜欢编程\",\n    \"我的目标是成为 AI 工程师\",\n    \"我叫什么名字?\"  # 第 1 轮应该被遗忘了\n]\n\nfor i, msg in enumerate(conversations):\n    print(f\"\\n=== 轮次 {i+1} ===\")\n    print(f\"用户: {msg}\")\n    response = conversation_window.predict(input=msg)\n    print(f\"AI: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: 总结Memory\n",
    "<!-- 实验 3: 总结记忆 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n\n# 自动总结历史\nmemory_summary = ConversationSummaryMemory(llm=ChatOpenAI(model=\"gpt-4o-mini\"))\nconversation_summary = ConversationChain(\n    llm=ChatOpenAI(model=\"gpt-4o-mini\"),\n    memory=memory_summary\n)\n\n# 多轮对话\nprint(\"=== 多轮对话 ===\")\nresponse1 = conversation_summary.predict(input=\"我叫小明,25 岁,在北京工作\")\nprint(f\"AI: {response1}\")\n\nresponse2 = conversation_summary.predict(input=\"我喜欢编程,最近在学 Python 和 AI\")\nprint(f\"AI: {response2}\")\n\nresponse3 = conversation_summary.predict(input=\"我的目标是成为一名优秀的 AI 工程师\")\nprint(f\"AI: {response3}\")\n\n# 查看总结\nprint(\"\\n=== 记忆总结 ===\")\nprint(memory_summary.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: 自DefineMemory管理\n",
    "<!-- 实验 4: 自定义记忆管理 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class CustomMemory:\n",
    "    def __init__(self, max_turns=10):\n",
    "        self.history = []\n",
    "        self.max_turns = max_turns\n",
    "        self.user_profile = {}\n",
    "    \n",
    "    def add_message(self, role: str, content: str):\n",
    "        self.history.append({\"role\": role, \"content\": content})\n",
    "        # 保持最近 N 轮\n",
    "        if len(self.history) > self.max_turns * 2:\n",
    "            self.history = self.history[-self.max_turns * 2:]\n",
    "    \n",
    "    def extract_user_info(self, text: str):\n",
    "        # 简单提取(实际应用中用 LLM)\n",
    "        if \"叫\" in text and \"我\" in text:\n",
    "            # 提取名字\n",
    "            pass\n",
    "    \n",
    "    def get_messages(self):\n",
    "        system_msg = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"你是一个友好的助手。用户信息: {json.dumps(self.user_profile, ensure_ascii=False)}\"\n",
    "        }\n",
    "        return [system_msg] + self.history\n",
    "\n",
    "# 使用\n",
    "memory = CustomMemory(max_turns=5)\n",
    "\n",
    "def chat(user_input: str):\n",
    "    memory.add_message(\"user\", user_input)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=memory.get_messages()\n",
    "    )\n",
    "    \n",
    "    assistant_reply = response.choices[0].message.content\n",
    "    memory.add_message(\"assistant\", assistant_reply)\n",
    "    \n",
    "    return assistant_reply\n",
    "\n",
    "# Test\n",
    "print(\"=== 自定义记忆聊天 ===\")\n",
    "print(\"用户: 我叫小明\")\n",
    "print(f\"AI: {chat('我叫小明')}\")\n",
    "\n",
    "print(\"\\n用户: 我喜欢编程\")\n",
    "print(f\"AI: {chat('我喜欢编程')}\")\n",
    "\n",
    "print(\"\\n用户: 我叫什么名字?\")\n",
    "print(f\"AI: {chat('我叫什么名字?')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 5: VectorMemory\n",
    "<!-- 实验 5: 向量记忆 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Create向量存储\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    persist_directory=\"./memory_db\"\n",
    ")\n",
    "\n",
    "# Create向量记忆\n",
    "memory_vector = VectorStoreRetrieverMemory(\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    ")\n",
    "\n",
    "# Save对话\n",
    "memory_vector.save_context(\n",
    "    {\"input\": \"我喜欢 Python 编程\"},\n",
    "    {\"output\": \"Python 是一门很棒的语言!\"}\n",
    ")\n",
    "\n",
    "memory_vector.save_context(\n",
    "    {\"input\": \"我在学习机器学习\"},\n",
    "    {\"output\": \"机器学习很有前景!\"}\n",
    ")\n",
    "\n",
    "memory_vector.save_context(\n",
    "    {\"input\": \"我最近在看深度学习的书\"},\n",
    "    {\"output\": \"深度学习是 AI 的核心技术。\"}\n",
    ")\n",
    "\n",
    "# 检索相关记忆\n",
    "print(\"=== 检索相关记忆 ===\")\n",
    "result = memory_vector.load_memory_variables({\"prompt\": \"我喜欢什么语言?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on Exercises\n",
    "<!-- 动手练习 -->\n",
    "\n",
    "1. **实现用户画像**: 从对话中提取并保存用户信息\n",
    "2. **持久化存储**: 将记忆保存到 Redis 或 MongoDB\n",
    "3. **混合记忆**: 结合短期、中期、长期记忆\n",
    "4. **记忆召回策略**: 根据相关性智能选择记忆\n",
    "\n",
    "---\n",
    "\n",
    "## 关键要点\n",
    "\n",
    "1. **三种短期记忆**: Buffer(全部)、Window(窗口)、Summary(总结)\n",
    "2. **长期记忆**: 用户画像、向量存储\n",
    "3. **权衡**: 记忆越多越好?不是!要平衡成本和效果\n",
    "4. **持久化**: 生产环境需要数据库存储\n",
    "\n",
    "---\n",
    "\n",
    "**恭喜!** 完成了 RAG & 记忆存储章节。\n",
    "\n",
    "**下一步**: 进入 [第 13 章:生产化部署](../../docs/13-production/index.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}