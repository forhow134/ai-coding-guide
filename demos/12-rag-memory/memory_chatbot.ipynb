{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 12.4 记忆聊天机器人\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-org/ai-first-app/blob/main/demos/12-rag-memory/memory_chatbot.ipynb)\n\n**预计 API 费用: ~$0.02**\n\n本 Notebook 实现带记忆的聊天机器人。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install -q langchain langchain-openai"]},{"cell_type":"markdown","metadata":{},"source":["## 实验 1: 基础对话记忆"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain.memory import ConversationBufferMemory\nfrom langchain_openai import ChatOpenAI\nfrom langchain.chains import ConversationChain\n\n# 创建记忆\nmemory = ConversationBufferMemory()\n\n# 创建对话链\nconversation = ConversationChain(\n    llm=ChatOpenAI(model=\"gpt-4o-mini\"),\n    memory=memory,\n    verbose=True\n)\n\n# 对话测试\nprint(\"=== 对话 1 ===\")\nresponse1 = conversation.predict(input=\"我叫小明\")\nprint(f\"AI: {response1}\")\n\nprint(\"\\n=== 对话 2 ===\")\nresponse2 = conversation.predict(input=\"我 25 岁,喜欢编程\")\nprint(f\"AI: {response2}\")\n\nprint(\"\\n=== 对话 3 ===\")\nresponse3 = conversation.predict(input=\"我叫什么名字?多大年纪?\")\nprint(f\"AI: {response3}\")\n\n# 查看记忆\nprint(\"\\n=== 记忆内容 ===\")\nprint(memory.buffer)"]},{"cell_type":"markdown","metadata":{},"source":["## 实验 2: 窗口记忆"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain.memory import ConversationBufferWindowMemory\n\n# 只保留最近 3 轮对话\nmemory_window = ConversationBufferWindowMemory(k=3)\nconversation_window = ConversationChain(\n    llm=ChatOpenAI(model=\"gpt-4o-mini\"),\n    memory=memory_window\n)\n\nconversations = [\n    \"我叫小明\",\n    \"我 25 岁\",\n    \"我在北京\",\n    \"我喜欢编程\",\n    \"我的目标是成为 AI 工程师\",\n    \"我叫什么名字?\"  # 第 1 轮应该被遗忘了\n]\n\nfor i, msg in enumerate(conversations):\n    print(f\"\\n=== 轮次 {i+1} ===\")\n    print(f\"用户: {msg}\")\n    response = conversation_window.predict(input=msg)\n    print(f\"AI: {response}\")"]},{"cell_type":"markdown","metadata":{},"source":["## 实验 3: 总结记忆"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain.memory import ConversationSummaryMemory\n\n# 自动总结历史\nmemory_summary = ConversationSummaryMemory(llm=ChatOpenAI(model=\"gpt-4o-mini\"))\nconversation_summary = ConversationChain(\n    llm=ChatOpenAI(model=\"gpt-4o-mini\"),\n    memory=memory_summary\n)\n\n# 多轮对话\nprint(\"=== 多轮对话 ===\")\nresponse1 = conversation_summary.predict(input=\"我叫小明,25 岁,在北京工作\")\nprint(f\"AI: {response1}\")\n\nresponse2 = conversation_summary.predict(input=\"我喜欢编程,最近在学 Python 和 AI\")\nprint(f\"AI: {response2}\")\n\nresponse3 = conversation_summary.predict(input=\"我的目标是成为一名优秀的 AI 工程师\")\nprint(f\"AI: {response3}\")\n\n# 查看总结\nprint(\"\\n=== 记忆总结 ===\")\nprint(memory_summary.buffer)"]},{"cell_type":"markdown","metadata":{},"source":["## 实验 4: 自定义记忆管理"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from openai import OpenAI\nimport json\n\nclient = OpenAI()\n\nclass CustomMemory:\n    def __init__(self, max_turns=10):\n        self.history = []\n        self.max_turns = max_turns\n        self.user_profile = {}\n    \n    def add_message(self, role: str, content: str):\n        self.history.append({\"role\": role, \"content\": content})\n        # 保持最近 N 轮\n        if len(self.history) > self.max_turns * 2:\n            self.history = self.history[-self.max_turns * 2:]\n    \n    def extract_user_info(self, text: str):\n        # 简单提取(实际应用中用 LLM)\n        if \"叫\" in text and \"我\" in text:\n            # 提取名字\n            pass\n    \n    def get_messages(self):\n        system_msg = {\n            \"role\": \"system\",\n            \"content\": f\"你是一个友好的助手。用户信息: {json.dumps(self.user_profile, ensure_ascii=False)}\"\n        }\n        return [system_msg] + self.history\n\n# 使用\nmemory = CustomMemory(max_turns=5)\n\ndef chat(user_input: str):\n    memory.add_message(\"user\", user_input)\n    \n    response = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=memory.get_messages()\n    )\n    \n    assistant_reply = response.choices[0].message.content\n    memory.add_message(\"assistant\", assistant_reply)\n    \n    return assistant_reply\n\n# 测试\nprint(\"=== 自定义记忆聊天 ===\")\nprint(\"用户: 我叫小明\")\nprint(f\"AI: {chat('我叫小明')}\")\n\nprint(\"\\n用户: 我喜欢编程\")\nprint(f\"AI: {chat('我喜欢编程')}\")\n\nprint(\"\\n用户: 我叫什么名字?\")\nprint(f\"AI: {chat('我叫什么名字?')}\")"]},{"cell_type":"markdown","metadata":{},"source":["## 实验 5: 向量记忆"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain.memory import VectorStoreRetrieverMemory\nfrom langchain.vectorstores import Chroma\nfrom langchain_openai import OpenAIEmbeddings\n\n# 创建向量存储\nvectorstore = Chroma(\n    embedding_function=OpenAIEmbeddings(),\n    persist_directory=\"./memory_db\"\n)\n\n# 创建向量记忆\nmemory_vector = VectorStoreRetrieverMemory(\n    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3})\n)\n\n# 保存对话\nmemory_vector.save_context(\n    {\"input\": \"我喜欢 Python 编程\"},\n    {\"output\": \"Python 是一门很棒的语言!\"}\n)\n\nmemory_vector.save_context(\n    {\"input\": \"我在学习机器学习\"},\n    {\"output\": \"机器学习很有前景!\"}\n)\n\nmemory_vector.save_context(\n    {\"input\": \"我最近在看深度学习的书\"},\n    {\"output\": \"深度学习是 AI 的核心技术。\"}\n)\n\n# 检索相关记忆\nprint(\"=== 检索相关记忆 ===\")\nresult = memory_vector.load_memory_variables({\"prompt\": \"我喜欢什么语言?\"})\nprint(result)"]},{"cell_type":"markdown","metadata":{},"source":["## 动手练习\n\n1. **实现用户画像**: 从对话中提取并保存用户信息\n2. **持久化存储**: 将记忆保存到 Redis 或 MongoDB\n3. **混合记忆**: 结合短期、中期、长期记忆\n4. **记忆召回策略**: 根据相关性智能选择记忆\n\n---\n\n## 关键要点\n\n1. **三种短期记忆**: Buffer(全部)、Window(窗口)、Summary(总结)\n2. **长期记忆**: 用户画像、向量存储\n3. **权衡**: 记忆越多越好?不是!要平衡成本和效果\n4. **持久化**: 生产环境需要数据库存储\n\n---\n\n**恭喜!** 完成了 RAG & 记忆存储章节。\n\n**下一步**: 进入 [第 13 章:生产化部署](../../docs/13-production/index.md)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":2}
