{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.3 高级 RAG 技术\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/forhow134/ai-coding-guide/blob/main/demos/12-rag-memory/advanced_rag.ipynb)\n",
    "\n",
    "**预计 API 费用: ~$0.05**\n",
    "\n",
    "本 Notebook 演示高级 RAG 技术:分块策略、重排序、混合搜索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-openai chromadb cohere rank-bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: 分块策略Comparison\n",
    "<!-- 实验 1: 分块策略对比 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import (\n    CharacterTextSplitter,\n    RecursiveCharacterTextSplitter,\n    TokenTextSplitter\n)\n\ntext = \"\"\"\nPython 异常处理最佳实践\n\n1. 使用具体的异常类型\n不要捕获所有异常,应该捕获具体的异常类型。\n\n2. 避免空的 except 块\n空的 except 块会隐藏错误。\n\n3. 使用 finally 清理资源\nfinally 块总是会执行,适合清理资源。\n\"\"\"\n\n# 策略 1: 固定字符数\nprint(\"=== 策略 1: 固定字符数 ===\")\nsplitter1 = CharacterTextSplitter(chunk_size=100, chunk_overlap=20)\nchunks1 = splitter1.split_text(text)\nfor i, chunk in enumerate(chunks1):\n    print(f\"Chunk {i+1}: {chunk[:50]}...\\n\")\n\n# 策略 2: 递归分块(推荐)\nprint(\"\\n=== 策略 2: 递归分块 ===\")\nsplitter2 = RecursiveCharacterTextSplitter(\n    chunk_size=100,\n    chunk_overlap=20,\n    separators=[\"\\n\\n\", \"\\n\", \"。\", \" \", \"\"]\n)\nchunks2 = splitter2.split_text(text)\nfor i, chunk in enumerate(chunks2):\n    print(f\"Chunk {i+1}: {chunk[:50]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: 重排序 (Reranking)\n",
    "<!-- 实验 2: 重排序 (Reranking) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# 准备文档\n",
    "docs_content = [\n",
    "    \"Python 使用 try-except 处理异常\",\n",
    "    \"Java 使用 try-catch 处理异常\",\n",
    "    \"异常情况下系统会重启\",\n",
    "    \"Python 的异常处理非常灵活\",\n",
    "    \"异常天气可能导致航班延误\"\n",
    "]\n",
    "\n",
    "from langchain.schema import Document\n",
    "docs = [Document(page_content=content) for content in docs_content]\n",
    "\n",
    "# Create向量库\n",
    "vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings())\n",
    "\n",
    "# Query\n",
    "query = \"Python 如何处理异常?\"\n",
    "\n",
    "# 向量搜索 Top-5\n",
    "print(\"=== 向量搜索结果 ===\")\n",
    "results_vector = vectorstore.similarity_search_with_score(query, k=5)\n",
    "for i, (doc, score) in enumerate(results_vector):\n",
    "    print(f\"{i+1}. [{score:.4f}] {doc.page_content}\")\n",
    "\n",
    "# Rerank\n",
    "print(\"\\n=== Rerank 后结果 ===\")\n",
    "co = cohere.Client(\"your-cohere-api-key\")  # 需要 Cohere API key\n",
    "rerank_results = co.rerank(\n",
    "    query=query,\n",
    "    documents=docs_content,\n",
    "    top_n=3,\n",
    "    model=\"rerank-multilingual-v3.0\"\n",
    ")\n",
    "\n",
    "for i, result in enumerate(rerank_results.results):\n",
    "    print(f\"{i+1}. [{result.relevance_score:.4f}] {docs_content[result.index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: 混合Search (Hybrid Search)\n",
    "<!-- 实验 3: 混合搜索 (Hybrid Search) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import jieba\n",
    "\n",
    "# BM25 关键词搜索\n",
    "class BM25Searcher:\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        # 分词\n",
    "        tokenized_docs = [list(jieba.cut(doc)) for doc in documents]\n",
    "        self.bm25 = BM25Okapi(tokenized_docs)\n",
    "    \n",
    "    def search(self, query, k=3):\n",
    "        tokenized_query = list(jieba.cut(query))\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        top_k_idx = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:k]\n",
    "        return [(self.documents[i], scores[i]) for i in top_k_idx]\n",
    "\n",
    "# 混合搜索\n",
    "def hybrid_search(query, vectorstore, bm25_searcher, k=3, alpha=0.5):\n",
    "    # 向量搜索\n",
    "    vector_results = vectorstore.similarity_search_with_score(query, k=k*2)\n",
    "    \n",
    "    # BM25 搜索\n",
    "    bm25_results = bm25_searcher.search(query, k=k*2)\n",
    "    \n",
    "    # 归一化并融合分数\n",
    "    combined = {}\n",
    "    \n",
    "    for doc, score in vector_results:\n",
    "        text = doc.page_content\n",
    "        combined[text] = combined.get(text, 0) + (1 - score) * alpha\n",
    "    \n",
    "    for text, score in bm25_results:\n",
    "        combined[text] = combined.get(text, 0) + score * (1 - alpha)\n",
    "    \n",
    "    # 排序\n",
    "    sorted_results = sorted(combined.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "    return sorted_results\n",
    "\n",
    "# Test\n",
    "bm25_searcher = BM25Searcher(docs_content)\n",
    "\n",
    "print(\"=== 混合搜索结果 ===\")\n",
    "hybrid_results = hybrid_search(query, vectorstore, bm25_searcher, k=3)\n",
    "for i, (doc, score) in enumerate(hybrid_results):\n",
    "    print(f\"{i+1}. [{score:.4f}] {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on Exercises\n",
    "<!-- 动手练习 -->\n",
    "\n",
    "1. **对比不同分块大小**: chunk_size 200 vs 500 vs 1000\n",
    "2. **调整混合搜索权重**: alpha 0.3 vs 0.5 vs 0.7\n",
    "3. **实现查询改写**: 用 LLM 改写模糊查询\n",
    "4. **添加元数据过滤**: 只搜索特定类别的文档\n",
    "\n",
    "---\n",
    "\n",
    "## 关键要点\n",
    "\n",
    "1. **递归分块最优**: 保持语义完整性\n",
    "2. **Reranking 提升精度**: 二次排序提升 Top-K 质量\n",
    "3. **混合搜索**: 向量 + BM25 兼顾语义和精确\n",
    "4. **权重调优**: alpha 参数影响搜索结果\n",
    "\n",
    "---\n",
    "\n",
    "**下一步**: [12.4 记忆管理](./memory_chatbot.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}