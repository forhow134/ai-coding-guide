{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 Function Calling åŸç†å®éªŒ\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-org/ai-first-app/blob/main/demos/07-function-calling/function_calling.ipynb)\n",
    "\n",
    "**é¢„è®¡ API è´¹ç”¨: ~$0.01**\n",
    "\n",
    "æœ¬ Notebook æ¼”ç¤º Function Calling çš„å®Œæ•´å·¥ä½œæµç¨‹,åŒ…æ‹¬å¤©æ°”æŸ¥è¯¢ã€æµå¼è¾“å‡ºç­‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"è¯·è¾“å…¥ä½ çš„ OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®éªŒ 1: åŸºç¡€ Function Calling\n",
    "\n",
    "å®ç°ä¸€ä¸ªç®€å•çš„å¤©æ°”æŸ¥è¯¢å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# 1. å®šä¹‰å·¥å…·\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"è·å–æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”ä¿¡æ¯\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"åŸå¸‚åç§°,å¦‚:åŒ—äº¬ã€ä¸Šæµ·ã€æ·±åœ³\"\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"æ¸©åº¦å•ä½\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# 2. å®ç°å·¥å…·å‡½æ•°(æ¨¡æ‹Ÿæ•°æ®)\n",
    "def get_weather(city: str, unit: str = \"celsius\"):\n",
    "    \"\"\"æ¨¡æ‹Ÿå¤©æ°” API(å®é™…åº”ç”¨ä¸­è°ƒç”¨çœŸå® API)\"\"\"\n",
    "    fake_data = {\n",
    "        \"åŒ—äº¬\": {\"temperature\": 15 if unit == \"celsius\" else 59, \"weather\": \"æ™´\", \"humidity\": 45},\n",
    "        \"ä¸Šæµ·\": {\"temperature\": 22 if unit == \"celsius\" else 72, \"weather\": \"å¤šäº‘\", \"humidity\": 65},\n",
    "        \"æ·±åœ³\": {\"temperature\": 28 if unit == \"celsius\" else 82, \"weather\": \"é›¨\", \"humidity\": 80},\n",
    "    }\n",
    "    return fake_data.get(city, {\"error\": f\"æœªæ‰¾åˆ°åŸå¸‚ {city} çš„å¤©æ°”æ•°æ®\"})\n",
    "\n",
    "# 3. æµ‹è¯•å•ä¸ªå·¥å…·è°ƒç”¨\n",
    "messages = [{\"role\": \"user\", \"content\": \"åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·?\"}]\n",
    "\n",
    "print(\"=== ç¬¬ 1 æ­¥: ç”¨æˆ·æé—® ===\")\n",
    "print(messages[0][\"content\"])\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "print(f\"\\n=== ç¬¬ 2 æ­¥: LLM åˆ¤æ–­éœ€è¦è°ƒç”¨å·¥å…· ===\")\n",
    "\n",
    "if message.tool_calls:\n",
    "    tool_call = message.tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    \n",
    "    print(f\"å·¥å…·: {function_name}\")\n",
    "    print(f\"å‚æ•°: {json.dumps(function_args, ensure_ascii=False)}\")\n",
    "    \n",
    "    # 4. æ‰§è¡Œå·¥å…·\n",
    "    print(f\"\\n=== ç¬¬ 3 æ­¥: æ‰§è¡Œå·¥å…· ===\")\n",
    "    result = get_weather(**function_args)\n",
    "    print(f\"å·¥å…·è¿”å›: {json.dumps(result, ensure_ascii=False)}\")\n",
    "    \n",
    "    # 5. å°†ç»“æœè¿”å› LLM\n",
    "    messages.append(message)\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"content\": json.dumps(result, ensure_ascii=False)\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n=== ç¬¬ 4 æ­¥: LLM ç”Ÿæˆæœ€ç»ˆå›ç­” ===\")\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    print(final_response.choices[0].message.content)\n",
    "else:\n",
    "    print(\"LLM åˆ¤æ–­ä¸éœ€è¦è°ƒç”¨å·¥å…·,ç›´æ¥å›ç­”:\")\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®éªŒ 2: å¤šè½®å·¥å…·è°ƒç”¨\n",
    "\n",
    "ç”¨æˆ·å¯èƒ½è¿ç»­é—®å¤šä¸ªåŸå¸‚çš„å¤©æ°”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def run_conversation(user_query: str, max_iterations: int = 5):\n",
    "    \"\"\"è¿è¡Œå¤šè½®å¯¹è¯,è‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": user_query}]\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        print(f\"\\n--- è¿­ä»£ {i+1} ---\")\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "        \n",
    "        message = response.choices[0].message\n",
    "        messages.append(message)\n",
    "        \n",
    "        if not message.tool_calls:\n",
    "            print(\"\\nâœ… æœ€ç»ˆå›ç­”:\")\n",
    "            print(message.content)\n",
    "            return message.content\n",
    "        \n",
    "        # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨\n",
    "        for tool_call in message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            print(f\"ğŸ”§ è°ƒç”¨å·¥å…·: {function_name}({function_args})\")\n",
    "            \n",
    "            result = get_weather(**function_args)\n",
    "            print(f\"ğŸ“Š è¿”å›: {json.dumps(result, ensure_ascii=False)}\")\n",
    "            \n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": json.dumps(result, ensure_ascii=False)\n",
    "            })\n",
    "    \n",
    "    return \"è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°\"\n",
    "\n",
    "# æµ‹è¯•\n",
    "run_conversation(\"åŒ—äº¬ã€ä¸Šæµ·ã€æ·±åœ³ä»Šå¤©å¤©æ°”å¦‚ä½•?å“ªä¸ªæœ€é€‚åˆå‡ºé—¨?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®éªŒ 3: tool_choice å‚æ•°æ§åˆ¶\n",
    "\n",
    "æ§åˆ¶ LLM æ˜¯å¦è°ƒç”¨å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "question = \"ä½ å¥½\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "# 1. auto: è‡ªåŠ¨åˆ¤æ–­\n",
    "print(\"=== tool_choice='auto' ===\")\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "print(f\"æ˜¯å¦è°ƒç”¨å·¥å…·: {bool(response.choices[0].message.tool_calls)}\")\n",
    "print(f\"å›ç­”: {response.choices[0].message.content}\\n\")\n",
    "\n",
    "# 2. none: å¼ºåˆ¶ä¸è°ƒç”¨å·¥å…·\n",
    "print(\"=== tool_choice='none' ===\")\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·?\"}],\n",
    "    tools=tools,\n",
    "    tool_choice=\"none\"\n",
    ")\n",
    "print(f\"æ˜¯å¦è°ƒç”¨å·¥å…·: {bool(response.choices[0].message.tool_calls)}\")\n",
    "print(f\"å›ç­”: {response.choices[0].message.content}\\n\")\n",
    "\n",
    "# 3. required: å¼ºåˆ¶è°ƒç”¨å·¥å…·\n",
    "print(\"=== tool_choice='required' ===\")\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"ä½ å¥½\"}],\n",
    "    tools=tools,\n",
    "    tool_choice=\"required\"\n",
    ")\n",
    "print(f\"æ˜¯å¦è°ƒç”¨å·¥å…·: {bool(response.choices[0].message.tool_calls)}\")\n",
    "if response.choices[0].message.tool_calls:\n",
    "    print(f\"è°ƒç”¨äº†: {response.choices[0].message.tool_calls[0].function.name}\\n\")\n",
    "\n",
    "# 4. æŒ‡å®šå·¥å…·\n",
    "print(\"=== tool_choice={æŒ‡å®šå·¥å…·} ===\")\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"ä»Šå¤©é€‚åˆå‡ºé—¨å—?\"}],\n",
    "    tools=tools,\n",
    "    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_weather\"}}\n",
    ")\n",
    "print(f\"æ˜¯å¦è°ƒç”¨å·¥å…·: {bool(response.choices[0].message.tool_calls)}\")\n",
    "if response.choices[0].message.tool_calls:\n",
    "    print(f\"è°ƒç”¨äº†: {response.choices[0].message.tool_calls[0].function.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®éªŒ 4: æµå¼è¾“å‡º(Streaming)\n",
    "\n",
    "Function Calling ä¹Ÿæ”¯æŒæµå¼è¾“å‡ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"åŒ—äº¬å¤©æ°”å¦‚ä½•?\"}]\n",
    "\n",
    "print(\"=== æµå¼è¾“å‡ºå·¥å…·è°ƒç”¨ ===\\n\")\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "tool_calls_buffer = []\n",
    "current_tool_call = None\n",
    "\n",
    "for chunk in stream:\n",
    "    delta = chunk.choices[0].delta\n",
    "    \n",
    "    if delta.tool_calls:\n",
    "        for tool_call_chunk in delta.tool_calls:\n",
    "            index = tool_call_chunk.index\n",
    "            \n",
    "            # åˆå§‹åŒ–å·¥å…·è°ƒç”¨\n",
    "            if len(tool_calls_buffer) <= index:\n",
    "                tool_calls_buffer.append({\n",
    "                    \"id\": \"\",\n",
    "                    \"function\": {\"name\": \"\", \"arguments\": \"\"}\n",
    "                })\n",
    "            \n",
    "            # ç´¯ç§¯æ•°æ®\n",
    "            if tool_call_chunk.id:\n",
    "                tool_calls_buffer[index][\"id\"] = tool_call_chunk.id\n",
    "            if tool_call_chunk.function.name:\n",
    "                tool_calls_buffer[index][\"function\"][\"name\"] = tool_call_chunk.function.name\n",
    "                print(f\"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_call_chunk.function.name}\")\n",
    "            if tool_call_chunk.function.arguments:\n",
    "                tool_calls_buffer[index][\"function\"][\"arguments\"] += tool_call_chunk.function.arguments\n",
    "                print(f\"   å‚æ•°ç‰‡æ®µ: {tool_call_chunk.function.arguments}\")\n",
    "\n",
    "print(\"\\n=== å®Œæ•´å·¥å…·è°ƒç”¨ ===\")\n",
    "for tool_call in tool_calls_buffer:\n",
    "    print(f\"ID: {tool_call['id']}\")\n",
    "    print(f\"å‡½æ•°: {tool_call['function']['name']}\")\n",
    "    print(f\"å‚æ•°: {tool_call['function']['arguments']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®éªŒ 5: å¤šä¸ªå·¥å…·ç»„åˆ\n",
    "\n",
    "å®šä¹‰å¤šä¸ªå·¥å…·,LLM è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# å®šä¹‰å¤šä¸ªå·¥å…·\n",
    "multi_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"è·å–åŸå¸‚çš„å®æ—¶å¤©æ°”\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\", \"description\": \"åŸå¸‚å\"}\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculator\",\n",
    "            \"description\": \"æ‰§è¡Œæ•°å­¦è®¡ç®—\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\"type\": \"string\", \"description\": \"æ•°å­¦è¡¨è¾¾å¼,å¦‚ '2+3*4'\"}\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_time\",\n",
    "            \"description\": \"è·å–å½“å‰æ—¶é—´\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"timezone\": {\"type\": \"string\", \"description\": \"æ—¶åŒº,å¦‚ 'Asia/Shanghai'\"}\n",
    "                },\n",
    "                \"required\": []\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# å®ç°å·¥å…·å‡½æ•°\n",
    "def calculator(expression: str):\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return {\"expression\": expression, \"result\": result}\n",
    "    except:\n",
    "        return {\"error\": \"è®¡ç®—é”™è¯¯\"}\n",
    "\n",
    "def get_time(timezone: str = \"Asia/Shanghai\"):\n",
    "    from datetime import datetime\n",
    "    return {\"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \"timezone\": timezone}\n",
    "\n",
    "# å·¥å…·è·¯ç”±\n",
    "available_functions = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"calculator\": calculator,\n",
    "    \"get_time\": get_time\n",
    "}\n",
    "\n",
    "# æµ‹è¯•ä¸åŒé—®é¢˜\n",
    "test_questions = [\n",
    "    \"åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·?\",\n",
    "    \"å¸®æˆ‘ç®—ä¸€ä¸‹ 123 * 456\",\n",
    "    \"ç°åœ¨å‡ ç‚¹äº†?\",\n",
    "    \"åŒ—äº¬å¤©æ°”å¦‚ä½•?é¡ºä¾¿å‘Šè¯‰æˆ‘ç°åœ¨å‡ ç‚¹\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"é—®é¢˜: {question}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        tools=multi_tools\n",
    "    )\n",
    "    \n",
    "    message = response.choices[0].message\n",
    "    \n",
    "    if message.tool_calls:\n",
    "        messages.append(message)\n",
    "        \n",
    "        for tool_call in message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            print(f\"\\nğŸ”§ è°ƒç”¨: {function_name}({function_args})\")\n",
    "            \n",
    "            func = available_functions[function_name]\n",
    "            result = func(**function_args)\n",
    "            \n",
    "            print(f\"ğŸ“Š ç»“æœ: {json.dumps(result, ensure_ascii=False)}\")\n",
    "            \n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": json.dumps(result, ensure_ascii=False)\n",
    "            })\n",
    "        \n",
    "        final_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nâœ… æœ€ç»ˆå›ç­”:\")\n",
    "        print(final_response.choices[0].message.content)\n",
    "    else:\n",
    "        print(f\"\\nç›´æ¥å›ç­”: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åŠ¨æ‰‹ç»ƒä¹ \n",
    "\n",
    "1. **æ·»åŠ æ–°å·¥å…·**: å®ç°ä¸€ä¸ª `search_web(query)` å·¥å…·(æ¨¡æ‹Ÿæœç´¢)\n",
    "2. **é”™è¯¯å¤„ç†**: å½“å·¥å…·è°ƒç”¨å¤±è´¥æ—¶,å¦‚ä½•å‘Šè¯‰ LLM?\n",
    "3. **å‚æ•°éªŒè¯**: åœ¨æ‰§è¡Œå·¥å…·å‰éªŒè¯å‚æ•°æ˜¯å¦åˆæ³•\n",
    "4. **æˆæœ¬ç»Ÿè®¡**: è®°å½•æ¯æ¬¡å¯¹è¯æ¶ˆè€—çš„ tokens å’Œæˆæœ¬\n",
    "\n",
    "---\n",
    "\n",
    "## å…³é”®è¦ç‚¹æ€»ç»“\n",
    "\n",
    "1. **Function Calling æ˜¯åä½œæ¨¡å¼**: LLM æå‡ºè°ƒç”¨è¯·æ±‚,ä½ çš„ä»£ç æ‰§è¡Œ\n",
    "2. **å·¥å…·å®šä¹‰ç”¨ JSON Schema**: æè¿°æ¸…æ¥šå‚æ•°ç±»å‹å’Œè¯´æ˜\n",
    "3. **tool_choice æ§åˆ¶è°ƒç”¨ç­–ç•¥**: auto | required | none | æŒ‡å®šå·¥å…·\n",
    "4. **æ”¯æŒæµå¼è¾“å‡º**: å®æ—¶æ¥æ”¶å·¥å…·è°ƒç”¨ä¿¡æ¯\n",
    "5. **å¤šå·¥å…·è‡ªåŠ¨é€‰æ‹©**: LLM æ ¹æ®é—®é¢˜è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å·¥å…·\n",
    "\n",
    "---\n",
    "\n",
    "**ä¸‹ä¸€æ­¥**: å­¦ä¹  [7.2 Tool Use å®æˆ˜](./tool_use.ipynb),å¯¹æ¯” OpenAI å’Œ Anthropic çš„å·¥å…·è°ƒç”¨æ–¹å¼ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
