{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# 7.3 å·¥å…·ç¼–æ’ä¸å›é€€\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-org/ai-first-app/blob/main/demos/07-function-calling/orchestration.ipynb)\n\n**é¢„è®¡ API è´¹ç”¨: ~$0.03**\n\nå¤šå·¥å…·ç¼–æ’ã€é‡è¯•æœºåˆ¶ã€å›é€€ç­–ç•¥ã€‚"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install -q openai"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\nfrom getpass import getpass\n\nif not os.environ.get('OPENAI_API_KEY'):\n    os.environ['OPENAI_API_KEY'] = getpass('OpenAI API Key: ')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## å®éªŒ 1: å·¥å…·é“¾ (Tool Chain)"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from openai import OpenAI\nimport json\n\nclient = OpenAI()\n\ntools = [\n    {'type': 'function', 'function': {'name': 'get_weather', 'description': 'è·å–å¤©æ°”', 'parameters': {'type': 'object', 'properties': {'city': {'type': 'string'}}, 'required': ['city']}}},\n    {'type': 'function', 'function': {'name': 'suggest_clothing', 'description': 'æ ¹æ®æ¸©åº¦æ¨èç©¿è¡£', 'parameters': {'type': 'object', 'properties': {'temperature': {'type': 'number'}}, 'required': ['temperature']}}}\n]\n\ndef get_weather(city: str):\n    return {'temperature': 5, 'weather': 'æ™´'}\n\ndef suggest_clothing(temperature: float):\n    if temperature < 10:\n        return {'suggestion': 'ç¾½ç»’æœ'}\n    elif temperature < 20:\n        return {'suggestion': 'æ¯›è¡£'}\n    return {'suggestion': 'Tæ¤'}\n\nfunctions = {'get_weather': get_weather, 'suggest_clothing': suggest_clothing}\n\nmessages = [{'role': 'user', 'content': 'åŒ—äº¬å¤©æ°”å¦‚ä½•?åº”è¯¥ç©¿ä»€ä¹ˆ?'}]\n\nfor i in range(5):\n    print(f'\\n=== è¿­ä»£ {i+1} ===')\n    response = client.chat.completions.create(model='gpt-4o-mini', messages=messages, tools=tools)\n    message = response.choices[0].message\n    messages.append(message)\n    \n    if not message.tool_calls:\n        print(f'âœ… {message.content}')\n        break\n    \n    for tc in message.tool_calls:\n        name = tc.function.name\n        args = json.loads(tc.function.arguments)\n        print(f'ğŸ”§ {name}({args})')\n        result = functions[name](**args)\n        print(f'ğŸ“Š {result}')\n        messages.append({'role': 'tool', 'tool_call_id': tc.id, 'content': json.dumps(result, ensure_ascii=False)})"]}
  ,
  {"cell_type": "markdown", "metadata": {}, "source": ["## å®éªŒ 2: é‡è¯•ä¸å›é€€"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time\nimport random\n\nclass ToolExecutor:\n    def __init__(self, max_retries=3):\n        self.max_retries = max_retries\n    \n    def execute_with_retry(self, func, args, fallback_func=None):\n        for attempt in range(self.max_retries):\n            try:\n                result = func(**args)\n                if 'error' not in result:\n                    return {'success': True, 'data': result}\n                raise Exception(result['error'])\n            except Exception as e:\n                print(f'å°è¯• {attempt+1} å¤±è´¥: {e}')\n                if attempt < self.max_retries - 1:\n                    time.sleep(2 ** attempt)\n        \n        if fallback_func:\n            print('åˆ‡æ¢åˆ°å¤‡ç”¨å·¥å…·')\n            return {'success': True, 'data': fallback_func(**args), 'fallback': True}\n        \n        return {'success': False, 'error': str(e)}\n\ndef get_weather_api(city: str):\n    if random.random() < 0.7:  # 70% æˆåŠŸç‡\n        raise Exception('API è¶…æ—¶')\n    return {'temperature': 15, 'source': 'API'}\n\ndef get_weather_cache(city: str):\n    return {'temperature': 15, 'source': 'cache'}\n\nexecutor = ToolExecutor()\nresult = executor.execute_with_retry(get_weather_api, {'city': 'åŒ—äº¬'}, get_weather_cache)\nprint(f'\\nç»“æœ: {result}')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## å…³é”®è¦ç‚¹\n\n1. **å·¥å…·é“¾**: å¤šè½®å¯¹è¯å®ç°é¡ºåºè°ƒç”¨\n2. **é‡è¯•æœºåˆ¶**: æŒ‡æ•°é€€é¿\n3. **å›é€€ç­–ç•¥**: ä¸»å·¥å…·å¤±è´¥ååˆ‡æ¢å¤‡ç”¨\n4. **max_iterations**: é˜²æ­¢æ­»å¾ªç¯\n\n---\n\n**ä¸‹ä¸€æ­¥**: å­¦ä¹ ç¬¬ 8 ç« å¤šæ¨¡æ€ AI"]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3"}},
 "nbformat": 4,
 "nbformat_minor": 2
}
