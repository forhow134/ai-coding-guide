{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.3 å¤š Agent ç ”ç©¶ç³»ç»Ÿ\n\næœ¬ç¬”è®°æœ¬æ„å»ºä¸€ä¸ªå®Œæ•´çš„ Researcher + Writer + Reviewer ç³»ç»Ÿã€‚\n\n**é¢„ä¼°æˆæœ¬**: ~$0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai requests -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\nfrom openai import OpenAI\n\nclient = OpenAI()\nprint('âœ“ Client initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define Shared Memory\n",
    "<!-- Step 1: å®šä¹‰ Shared Memory -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedMemory:\n    def __init__(self):\n        self.data = {\n            'topic': None,\n            'research_findings': None,\n            'draft_version': 0,\n            'current_draft': None,\n            'review_feedback': [],\n        }\n    \n    def set(self, key, value):\n        self.data[key] = value\n        print(f'ğŸ“ Memory updated: {key}')\n    \n    def get(self, key):\n        return self.data.get(key)\n    \n    def increment_version(self):\n        self.data['draft_version'] += 1\n        return self.data['draft_version']\n\nshared_memory = SharedMemory()\nprint('âœ“ Shared memory initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: åˆ›å»º Researcher Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher = client.beta.assistants.create(\n    name='Research Specialist',\n    instructions='''Research the topic thoroughly.\nSave findings and hand off to writer.''',\n    model='gpt-4o-mini',\n    tools=[],\n    handoffs=[{'type': 'handoff', 'target': 'writer'}],\n)\n\nprint(f'Researcher: {researcher.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: åˆ›å»º Writer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = client.beta.assistants.create(\n    name='Content Writer',\n    instructions='''Write a well-structured report.\nSave draft and hand off to reviewer.''',\n    model='gpt-4o-mini',\n    tools=[],\n    handoffs=[{'type': 'handoff', 'target': 'reviewer'}],\n)\n\nprint(f'Writer: {writer.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: åˆ›å»º Reviewer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer = client.beta.assistants.create(\n    name='Quality Reviewer',\n    instructions='''Review the draft and score it.\nIf score >= 8: hand off to coordinator.\nIf score < 8: hand off back to writer for revision.''',\n    model='gpt-4o-mini',\n    tools=[],\n    handoffs=[\n        {'type': 'handoff', 'target': 'writer'},\n        {'type': 'handoff', 'target': 'coordinator'},\n    ],\n)\n\nprint(f'Reviewer: {reviewer.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: æ¨¡æ‹Ÿç³»ç»ŸRun\n",
    "<!-- Step 5: æ¨¡æ‹Ÿç³»ç»Ÿè¿è¡Œ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_research_system(topic):\n    print('=== ç ”ç©¶ç³»ç»Ÿè¿è¡Œ ===')\n    print(f'Topic: {topic}\\n')\n    \n    print('[Step 1] Coordinator â†’ Researcher')\n    shared_memory.set('topic', topic)\n    \n    print('[Step 2] Researcher æœç´¢èµ„æ–™')\n    research = 'Research findings about ' + topic\n    shared_memory.set('research_findings', research)\n    print('  Handoff to writer\\n')\n    \n    print('[Step 3] Writer æ’°å†™åˆç¨¿')\n    shared_memory.increment_version()\n    draft_v1 = 'Draft v1 based on research'\n    shared_memory.set('current_draft', draft_v1)\n    print('  Handoff to reviewer\\n')\n    \n    print('[Step 4] Reviewer è¯„åˆ†: 7/10')\n    feedback = 'Needs more data and better structure'\n    shared_memory.data['review_feedback'].append({'score': 7, 'feedback': feedback})\n    print(f'  Feedback: {feedback}')\n    print('  Handoff back to writer\\n')\n    \n    print('[Step 5] Writer ä¿®æ”¹')\n    shared_memory.increment_version()\n    draft_v2 = 'Draft v2 - improved'\n    shared_memory.set('current_draft', draft_v2)\n    print('  Handoff to reviewer\\n')\n    \n    print('[Step 6] Reviewer è¯„åˆ†: 9/10')\n    shared_memory.data['review_feedback'].append({'score': 9, 'feedback': 'Approved'})\n    print('  Approved! Handoff to coordinator\\n')\n    \n    print('[Step 7] Coordinator è¿”å›æœ€ç»ˆæŠ¥å‘Š')\n    \n    return {\n        'status': 'success',\n        'draft_version': shared_memory.get('draft_version'),\n        'review_rounds': len(shared_memory.get('review_feedback')),\n        'final_draft': shared_memory.get('current_draft'),\n    }\n\nresult = simulate_research_system('AI Agent å¸‚åœºè¶‹åŠ¿ 2026')\nprint('\\n=== ç»“æœ ===')\nfor k, v in result.items():\n    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: å¯è§†åŒ–åä½œæµç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_workflow():\n    print('=== å·¥ä½œæµç¨‹å¯è§†åŒ– ===')\n    print()\n    print('User')\n    print('  â†“')\n    print('Coordinator')\n    print('  â†“')\n    print('Researcher (æœç´¢èµ„æ–™)')\n    print('  â†“')\n    print('Writer (æ’°å†™ v1)')\n    print('  â†“')\n    print('Reviewer (è¯„åˆ†: 7/10)')\n    print('  â†“ (éœ€è¦ä¿®æ”¹)')\n    print('Writer (æ’°å†™ v2)')\n    print('  â†“')\n    print('Reviewer (è¯„åˆ†: 9/10)')\n    print('  â†“ (é€šè¿‡)')\n    print('Coordinator')\n    print('  â†“')\n    print('User (æœ€ç»ˆæŠ¥å‘Š)')\n\nvisualize_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n\nä½ å·²ç»æŒæ¡äº†å¤š Agent ç³»ç»Ÿçš„å®Œæ•´å¼€å‘ï¼\n\n### å…³é”®ç»„ä»¶\n- **Shared Memory**: æ‰€æœ‰ Agent å…±äº«çŠ¶æ€\n- **Handoff**: ä»»åŠ¡åœ¨ Agent é—´æµè½¬\n- **è´¨é‡é—¨ç¦**: Reviewer æ§åˆ¶è¿­ä»£\n- **é˜²æ­¢æ— é™å¾ªç¯**: æœ€å¤§è¿­ä»£æ¬¡æ•°é™åˆ¶\n\n### è®¾è®¡ç»éªŒ\n- âœ“ å•ä¸€èŒè´£ï¼šæ¯ä¸ª Agent ä¸“æ³¨ä¸€ä»¶äº‹\n- âœ“ æ˜ç¡®çš„ Handoff æ¡ä»¶\n- âœ“ å…±äº«å†…å­˜é¿å…é‡å¤ä¼ é€’\n- âœ“ è®¾ç½®ä¸Šé™é˜²æ­¢æˆæœ¬å¤±æ§\n- âœ“ è¯¦ç»†æ—¥å¿—ä¾¿äºè°ƒè¯•\n\nç¬¬ 10 ç« å®Œæˆï¼ä¸‹ä¸€ç« å­¦ä¹ åè®®ç¯‡ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}