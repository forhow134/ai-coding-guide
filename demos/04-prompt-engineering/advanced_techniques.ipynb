{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 进阶 Prompt 技巧\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-org/ai-first-app/blob/main/demos/04-prompt-engineering/advanced_techniques.ipynb)\n",
    "\n",
    "**预计 API 费用：~$0.02**\n",
    "\n",
    "本 Notebook 演示 Few-shot、Chain-of-Thought、Self-Consistency 等进阶技巧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"请输入你的 OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验 1：Zero-shot vs Few-shot 对比\n",
    "\n",
    "对比没有示例（Zero-shot）和给出示例（Few-shot）的效果差异。\n",
    "\n",
    "**任务：情感分类**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# 测试用例（边界情况）\n",
    "test_cases = [\n",
    "    \"这个产品太棒了！用了一周非常满意。\",\n",
    "    \"质量太差了，用了两天就坏了，非常失望。\",\n",
    "    \"还行吧，凑合用，没什么特别的。\",\n",
    "    \"价格有点贵，但质量确实不错，总体还算满意。\",  # 混合情感\n",
    "    \"不推荐购买。\",  # 简短\n",
    "]\n",
    "\n",
    "print(\"=== Zero-shot（无示例） ===\")\n",
    "print()\n",
    "\n",
    "for comment in test_cases:\n",
    "    prompt = f\"判断评论情感（正面/负面/中性）：{comment}\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,  # 确定性输出\n",
    "    )\n",
    "    \n",
    "    result = response.choices[0].message.content\n",
    "    print(f\"评论: {comment}\")\n",
    "    print(f\"情感: {result}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Few-shot（有示例） ===\")\n",
    "print()\n",
    "\n",
    "# Few-shot Prompt 模板\n",
    "few_shot_template = \"\"\"\n",
    "判断评论的情感倾向（正面/负面/中性）。\n",
    "\n",
    "示例：\n",
    "评论：这个产品太棒了！用了一周非常满意。\n",
    "情感：正面\n",
    "\n",
    "评论：质量太差了，用了两天就坏了，非常失望。\n",
    "情感：负面\n",
    "\n",
    "评论：还行吧，凑合用，没什么特别的。\n",
    "情感：中性\n",
    "\n",
    "现在判断这条：\n",
    "评论：{comment}\n",
    "情感：\n",
    "\"\"\"\n",
    "\n",
    "for comment in test_cases:\n",
    "    prompt = few_shot_template.format(comment=comment)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "    )\n",
    "    \n",
    "    result = response.choices[0].message.content.strip()\n",
    "    print(f\"评论: {comment}\")\n",
    "    print(f\"情感: {result}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**观察：**\n",
    "- Zero-shot 在简单情况下表现不错，但遇到边界情况（混合情感、简短文本）容易出错\n",
    "- Few-shot 通过示例\"教会\"模型任务的模式，准确率明显提升\n",
    "- Few-shot 的缺点：消耗更多 token（示例也要付费）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验 2：Chain-of-Thought（思考链）\n",
    "\n",
    "让 AI \"把思考过程写出来\"，显著提升数学推理准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# 测试：数学问题\n",
    "math_problems = [\n",
    "    \"一个数乘以 3 再加 7 等于 28，这个数是多少？\",\n",
    "    \"小明有 15 个苹果，给了小红 3 个，又买了 8 个，现在有几个？\",\n",
    "    \"一件衣服原价 200 元，打 8 折后又减 20 元，最终多少钱？\",\n",
    "]\n",
    "\n",
    "print(\"=== 直接提问（容易出错） ===\")\n",
    "print()\n",
    "\n",
    "for problem in math_problems:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": problem}],\n",
    "        temperature=0,\n",
    "    )\n",
    "    \n",
    "    result = response.choices[0].message.content\n",
    "    print(f\"问题: {problem}\")\n",
    "    print(f\"回答: {result}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Chain-of-Thought（逐步推理） ===\")\n",
    "print()\n",
    "\n",
    "for problem in math_problems:\n",
    "    prompt = f\"\"\"\n",
    "{problem}\n",
    "\n",
    "请一步步思考：\n",
    "1. 列出方程或计算步骤\n",
    "2. 逐步求解\n",
    "3. 验证答案\n",
    "\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "    )\n",
    "    \n",
    "    result = response.choices[0].message.content\n",
    "    print(f\"问题: {problem}\")\n",
    "    print(f\"推理过程:\\n{result}\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zero-shot CoT：只加一句话**\n",
    "\n",
    "最简单的 CoT 技巧：加一句 \"Let's think step by step.\" 或 \"让我们一步步思考。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Zero-shot CoT（魔法咒语） ===\")\n",
    "print()\n",
    "\n",
    "for problem in math_problems:\n",
    "    prompt = f\"{problem}\\n\\n让我们一步步思考。\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "    )\n",
    "    \n",
    "    result = response.choices[0].message.content\n",
    "    print(f\"问题: {problem}\")\n",
    "    print(f\"推理:\\n{result}\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Few-shot CoT：给出推理示例**\n",
    "\n",
    "最强效果：给出包含推理过程的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Few-shot CoT（带推理的示例） ===\")\n",
    "print()\n",
    "\n",
    "few_shot_cot_template = \"\"\"\n",
    "请解决数学问题，并写出推理步骤。\n",
    "\n",
    "问题：小明有 15 个苹果，给了小红 3 个，又买了 8 个，现在有几个？\n",
    "推理：\n",
    "- 初始：15 个\n",
    "- 给出：15 - 3 = 12 个\n",
    "- 买入：12 + 8 = 20 个\n",
    "答案：20 个\n",
    "\n",
    "问题：一件衣服原价 200 元，打 8 折后又减 20 元，最终多少钱？\n",
    "推理：\n",
    "- 打折：200 × 0.8 = 160 元\n",
    "- 再减：160 - 20 = 140 元\n",
    "答案：140 元\n",
    "\n",
    "现在解决这个问题：\n",
    "问题：{problem}\n",
    "推理：\n",
    "\"\"\"\n",
    "\n",
    "test_problem = \"一个数乘以 3 再加 7 等于 28，这个数是多少？\"\n",
    "prompt = few_shot_cot_template.format(problem=test_problem)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(f\"问题: {test_problem}\")\n",
    "print(f\"\\n推理:\\n{response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**关键洞察：**\n",
    "- CoT 让模型\"展示草稿纸\"，减少跳步错误\n",
    "- 对数学、逻辑推理任务，准确率提升 30%-50%\n",
    "- 代价：输出 token 数增加（推理过程也要付费）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验 3：Self-Consistency（自洽性投票）\n",
    "\n",
    "生成多个答案，投票选择最常见的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def self_consistency(question: str, n: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Self-Consistency: 生成多个答案并投票\n",
    "    \"\"\"\n",
    "    prompt = f\"{question}\\n\\n让我们一步步思考。最后用'答案：X'的格式给出最终答案。\"\n",
    "    \n",
    "    answers = []\n",
    "    print(f\"生成 {n} 个答案...\\n\")\n",
    "    \n",
    "    for i in range(n):\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,  # 提高多样性\n",
    "        )\n",
    "        \n",
    "        full_response = response.choices[0].message.content\n",
    "        \n",
    "        # 提取最终答案（假设格式为\"答案：X\"）\n",
    "        match = re.search(r'答案[：:](.*?)(?:\\n|$)', full_response)\n",
    "        if match:\n",
    "            final_answer = match.group(1).strip()\n",
    "        else:\n",
    "            # 如果没有找到标记，取最后一行\n",
    "            final_answer = full_response.strip().split('\\n')[-1]\n",
    "        \n",
    "        answers.append(final_answer)\n",
    "        print(f\"答案 {i+1}: {final_answer}\")\n",
    "    \n",
    "    # 投票\n",
    "    counter = Counter(answers)\n",
    "    most_common = counter.most_common(1)[0]\n",
    "    \n",
    "    print(f\"\\n投票结果：{dict(counter)}\")\n",
    "    print(f\"最终答案：{most_common[0]} (出现 {most_common[1]}/{n} 次)\")\n",
    "    \n",
    "    return most_common[0]\n",
    "\n",
    "# 测试\n",
    "question = \"一个数乘以 3 再加 7 等于 28，这个数是多少？\"\n",
    "result = self_consistency(question, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试更复杂的问题\n",
    "question2 = \"\"\"\n",
    "一个班级有 30 名学生。其中：\n",
    "- 60% 的学生喜欢数学\n",
    "- 50% 的学生喜欢英语\n",
    "- 20% 的学生两门都喜欢\n",
    "\n",
    "问：有多少学生至少喜欢一门课？\n",
    "\"\"\"\n",
    "\n",
    "result2 = self_consistency(question2, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Self-Consistency 的权衡：**\n",
    "\n",
    "| 优点 | 缺点 |\n",
    "|-----|------|\n",
    "| ✅ 准确率大幅提升（尤其是复杂推理） | ❌ API 成本翻 5-10 倍 |\n",
    "| ✅ 适合高风险场景（金融计算、医疗诊断） | ❌ 响应时间变慢 |\n",
    "| ✅ 可以发现模型\"犹豫\"的情况 | ❌ 不适合开放式问题 |\n",
    "\n",
    "**适用场景：**\n",
    "- 选择题、判断题\n",
    "- 数学计算题\n",
    "- 需要高准确率的分类任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验 4：综合对比实验\n",
    "\n",
    "同一个任务，对比所有技巧的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# 测试任务：情感分类（混合情感）\n",
    "test_case = \"价格有点贵，但质量确实不错，总体还算满意。\"\n",
    "\n",
    "print(\"测试评论：\", test_case)\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# 1. Zero-shot\n",
    "prompt_zero = f\"判断评论情感（正面/负面/中性）：{test_case}\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt_zero}],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(\"=== 1. Zero-shot ===\")\n",
    "print(f\"结果: {response.choices[0].message.content}\")\n",
    "print(f\"Token 用量: {response.usage.total_tokens}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Few-shot\n",
    "prompt_few = f\"\"\"\n",
    "判断评论情感（正面/负面/中性）。\n",
    "\n",
    "示例：\n",
    "评论：这个产品太棒了！\n",
    "情感：正面\n",
    "\n",
    "评论：质量太差，非常失望。\n",
    "情感：负面\n",
    "\n",
    "评论：还行吧，凑合用。\n",
    "情感：中性\n",
    "\n",
    "现在判断：\n",
    "评论：{test_case}\n",
    "情感：\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt_few}],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(\"=== 2. Few-shot ===\")\n",
    "print(f\"结果: {response.choices[0].message.content}\")\n",
    "print(f\"Token 用量: {response.usage.total_tokens}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Chain-of-Thought\n",
    "prompt_cot = f\"\"\"\n",
    "判断评论情感（正面/负面/中性）。\n",
    "\n",
    "示例：\n",
    "评论：这个产品太棒了！\n",
    "分析：用词\"太棒了\"表达强烈正面情绪。\n",
    "情感：正面\n",
    "\n",
    "评论：质量太差，非常失望。\n",
    "分析：用词\"太差\"和\"失望\"都是负面词汇，没有正面内容。\n",
    "情感：负面\n",
    "\n",
    "评论：还行吧，凑合用。\n",
    "分析：用词\"还行\"和\"凑合\"表示勉强接受，不是明确的正面或负面。\n",
    "情感：中性\n",
    "\n",
    "现在判断：\n",
    "评论：{test_case}\n",
    "分析：\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt_cot}],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(\"=== 3. Chain-of-Thought ===\")\n",
    "print(f\"结果:\\n{response.choices[0].message.content}\")\n",
    "print(f\"Token 用量: {response.usage.total_tokens}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 动手练习\n",
    "\n",
    "1. **测试 Few-shot 的示例数量**：对比 2 个、3 个、5 个示例的效果差异\n",
    "2. **CoT 变体**：试试\"Let's think step by step\"的英文版本，对比中文版本效果\n",
    "3. **Self-Consistency 参数调优**：试试 n=3、n=5、n=10，观察准确率和成本的权衡\n",
    "4. **创建自己的 Few-shot 模板**：为\"代码 bug 分类\"（语法错误/逻辑错误/性能问题）创建 Few-shot 模板"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关键要点总结\n",
    "\n",
    "1. **Few-shot**：给 3-5 个示例，适合分类、格式化任务，成本适中\n",
    "2. **Chain-of-Thought**：加\"让我们一步步思考\"，数学推理准确率提升 30%-50%\n",
    "3. **Self-Consistency**：生成 5-10 个答案投票，适合高风险场景，成本翻倍\n",
    "4. **成本权衡**：进阶技巧会显著增加 token 消耗，根据场景选择\n",
    "5. **组合使用**：Few-shot + CoT 效果最好，但成本最高\n",
    "\n",
    "**选择指南：**\n",
    "\n",
    "| 场景 | 推荐技巧 |\n",
    "|-----|----------|\n",
    "| 简单分类 | Few-shot |\n",
    "| 数学推理 | CoT |\n",
    "| 高风险决策 | Self-Consistency |\n",
    "| 复杂推理 | Few-shot + CoT |\n",
    "\n",
    "---\n",
    "\n",
    "**下一步：** 学习 [4.3 结构化输出](./structured_output.ipynb)，让 AI 输出可靠的 JSON。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
