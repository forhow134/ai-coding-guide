# 2.3 èšåˆå¹³å°ä¸ç½‘å…³ <DifficultyBadge level="intermediate" /> <CostBadge cost="$0" />

> æƒ³è±¡ä½ æœ‰ 10 ä¸ª AI æ¨¡å‹ï¼Œä½†å®ƒä»¬è¯´ç€ 10 ç§"æ–¹è¨€"... æ¬¢è¿æ¥åˆ° **AI è¶…å¸‚**ï¼Œä¸€ä¸ªæ¥å£æå®šæ‰€æœ‰æ¨¡å‹ï¼

> å‰ç½®çŸ¥è¯†ï¼š1.2 å…è´¹æ–¹æ¡ˆä¸é›¶æˆæœ¬èµ·æ­¥ï¼Œ2.2 ä¸»æµæ¨¡å‹æä¾›å•†

### ä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿï¼ˆProblemï¼‰

::: warning API é€‚é…åœ°ç‹±
ä½ åˆšå†™å®Œè°ƒç”¨ OpenAI çš„ä»£ç ï¼Œäº§å“ç»ç†è¯´ï¼š"æˆ‘ä»¬è¦å¯¹æ¯”ä¸€ä¸‹ Claude å’Œ Gemini çš„æ•ˆæœã€‚"

ä½ ï¼šğŸ˜± "é‚£æˆ‘è¦æ”¹ä¸‰å¥—ä»£ç ï¼Ÿï¼"
:::

ä¸Šä¸€èŠ‚æˆ‘ä»¬å¯¹æ¯”äº†ä¸‰å®¶æ¨¡å‹æä¾›å•†ï¼Œä½†å‘ç°ä¸€ä¸ªè¦å‘½çš„é—®é¢˜ï¼š**æ¯å®¶ API æ ¼å¼éƒ½ä¸åŒ**ã€‚

```python
# OpenAI / DeepSeekï¼ˆå…¼å®¹ OpenAIï¼‰
from openai import OpenAI
client = OpenAI()
response = client.chat.completions.create(
    model="gpt-4.1-mini",
    messages=[{"role": "user", "content": "ä½ å¥½"}],
)

# Google Gemini
from google import genai
client = genai.Client()
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents="ä½ å¥½",
)

# Anthropic Claude
import anthropic
client = anthropic.Anthropic()
response = client.messages.create(
    model="claude-opus-4.6",
    max_tokens=1024,
    messages=[{"role": "user", "content": "ä½ å¥½"}],
)
```

**è¿™å¸¦æ¥ä¸‰ä¸ªé—®é¢˜ï¼š**

1. **ä»£ç ç»´æŠ¤æˆæœ¬é«˜**ï¼šæƒ³åˆ‡æ¢æ¨¡å‹æä¾›å•†ï¼Œéœ€è¦æ”¹å¤§é‡ä»£ç 
2. **æ¨¡å‹é™çº§å›°éš¾**ï¼šGPT-4o è°ƒç”¨å¤±è´¥æ—¶ï¼Œæƒ³è‡ªåŠ¨é™çº§åˆ° GPT-4o-miniï¼Œéœ€è¦æ‰‹å†™ try-except é€»è¾‘
3. **å¤šæ¨¡å‹å¯¹æ¯”éº»çƒ¦**ï¼šæƒ³åŒæ—¶å¯¹æ¯” 10 ä¸ªæ¨¡å‹çš„å›ç­”ï¼Œè¦å†™ 10 å¥—ä»£ç 

è¿™å°±æ˜¯è½¯ä»¶å·¥ç¨‹ä¸­çš„ **N Ã— M é—®é¢˜**ï¼š

```mermaid
graph LR
    subgraph "æ²¡æœ‰èšåˆå¹³å°"
        A1["ä½ çš„åº”ç”¨ 1"] --> B1["OpenAI SDK"]
        A1 --> B2["Google SDK"]
        A1 --> B3["Anthropic SDK"]
        
        A2["ä½ çš„åº”ç”¨ 2"] --> B1
        A2 --> B2
        A2 --> B3
        
        A3["ä½ çš„åº”ç”¨ 3"] --> B1
        A3 --> B2
        A3 --> B3
    end
    
    style A1 fill:#ffe1e1
    style A2 fill:#ffe1e1
    style A3 fill:#ffe1e1
```

å¦‚æœä½ æœ‰ **N ä¸ªåº”ç”¨** å’Œ **M ä¸ªæ¨¡å‹æä¾›å•†**ï¼Œéœ€è¦ç»´æŠ¤ **N Ã— M** å¥—ä»£ç ï¼

**èšåˆå¹³å°è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼š**

```mermaid
graph LR
    subgraph "ä½¿ç”¨èšåˆå¹³å°"
        A1["ä½ çš„åº”ç”¨ 1"] --> C["èšåˆå¹³å°<br/>OpenRouter / ZenMux"]
        A2["ä½ çš„åº”ç”¨ 2"] --> C
        A3["ä½ çš„åº”ç”¨ 3"] --> C
        
        C --> B1["OpenAI"]
        C --> B2["Google"]
        C --> B3["Anthropic"]
        C --> B4["DeepSeek"]
        C --> B5["..."]
    end
    
    style C fill:#e1ffe1
```

ä½ åªéœ€è¦å¯¹æ¥ **1 ä¸ªç»Ÿä¸€æ¥å£**ï¼Œå°±èƒ½è°ƒç”¨æ‰€æœ‰æ¨¡å‹ï¼Œå¤æ‚åº¦ä» **N Ã— M** é™ä½åˆ° **N + M**ã€‚

### å®ƒæ˜¯ä»€ä¹ˆï¼Ÿï¼ˆConceptï¼‰

::: tip ç±»æ¯”æ—¶é—´ï¼šAI è¶…å¸‚
ä¼ ç»Ÿæ–¹å¼ï¼šä½ è¦ä¹°å¯ä¹ï¼Œå¾—è·‘å¯å£å¯ä¹ä¸“å–åº—ï¼›è¦ä¹°è–¯ç‰‡ï¼Œå¾—è·‘ä¹äº‹ä¸“å–åº—...

èšåˆå¹³å°ï¼šç›´æ¥å»æ²ƒå°”ç›ï¼Œæ‰€æœ‰å“ç‰Œä¸€æ¬¡æå®šï¼Œè¿˜èƒ½å¯¹æ¯”ä»·æ ¼ï¼

**èšåˆå¹³å° = AI æ¨¡å‹çš„æ²ƒå°”ç›è¶…å¸‚** ğŸ›’
:::

èšåˆå¹³å°æ˜¯"AI æ¨¡å‹çš„ API ç½‘å…³"ï¼Œæä¾›ç»Ÿä¸€çš„æ¥å£æ ¼å¼ï¼ˆé€šå¸¸å…¼å®¹ OpenAI APIï¼‰æ¥è°ƒç”¨å¤šå®¶æ¨¡å‹ã€‚

**ä¸»æµèšåˆå¹³å°å¯¹æ¯”ï¼š**

| å¹³å° | ç±»å‹ | æ”¯æŒæ¨¡å‹æ•° | æ ¸å¿ƒä¼˜åŠ¿ | ä»˜è´¹æ¨¡å¼ |
|-----|------|-----------|---------|---------|
| **OpenRouter** | ç¬¬ä¸‰æ–¹èšåˆ | 200+ | è‡ªåŠ¨é€‰æœ€ä¼˜æ¨¡å‹ã€ä»·æ ¼é€æ˜ | æŒ‰ç”¨é‡ä»˜è´¹ï¼ˆæ— åŠ ä»·ï¼‰ |
| **ZenMux** | ç¬¬ä¸‰æ–¹èšåˆ | 50+ | å›½å†…å¯ç”¨ã€æ”¯æŒæ”¯ä»˜å® | æŒ‰ç”¨é‡ä»˜è´¹ |
| **Azure OpenAI** | äº‘å¹³å° | 10+ | ä¼ä¸šçº§ SLAã€æ•°æ®åˆè§„ | è®¢é˜… + æŒ‰é‡ |
| **AWS Bedrock** | äº‘å¹³å° | 15+ | ä¸ AWS ç”Ÿæ€é›†æˆ | æŒ‰ç”¨é‡ä»˜è´¹ |
| **GCP Vertex AI** | äº‘å¹³å° | 10+ | ä¸ GCP ç”Ÿæ€é›†æˆ | æŒ‰ç”¨é‡ä»˜è´¹ |

**èšåˆå¹³å°çš„ä¸‰å¤§èƒ½åŠ›ï¼š**

1. **ç»Ÿä¸€æ¥å£**ï¼šä¸€å¥—ä»£ç è°ƒç”¨æ‰€æœ‰æ¨¡å‹
2. **æ™ºèƒ½è·¯ç”±**ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹æˆ–é™çº§å¤‡é€‰
3. **æˆæœ¬ä¼˜åŒ–**ï¼šå¯¹æ¯”ä»·æ ¼ã€è‡ªåŠ¨é€‰æ‹©æ€§ä»·æ¯”æœ€é«˜çš„æ¨¡å‹

**OpenRouter çš„æ ¸å¿ƒç‰¹æ€§ï¼š**

```mermaid
graph TB
    A["ä½ çš„ä»£ç <br/>OpenAI SDK"] --> B["OpenRouter API"]
    
    B --> C["è‡ªåŠ¨è·¯ç”±"]
    C --> C1["æŒ‰ä»·æ ¼é€‰"]
    C --> C2["æŒ‰é€Ÿåº¦é€‰"]
    C --> C3["æŒ‰è´¨é‡é€‰"]
    
    B --> D["Fallback é™çº§"]
    D --> D1["ä¸»æ¨¡å‹å¤±è´¥"]
    D --> D2["è‡ªåŠ¨åˆ‡æ¢å¤‡é€‰"]
    
    B --> E["200+ æ¨¡å‹"]
    E --> E1["OpenAI"]
    E --> E2["Anthropic"]
    E --> E3["Google"]
    E --> E4["DeepSeek"]
    E --> E5["å¼€æºæ¨¡å‹"]
    
    style B fill:#e1ffe1
```

**äº‘å¹³å° vs ç¬¬ä¸‰æ–¹èšåˆå¹³å°ï¼š**

| ç»´åº¦ | OpenRouter / ZenMux | Azure / AWS / GCP |
|-----|---------------------|-------------------|
| **æ¨¡å‹æ•°é‡** | 200+ | 10-20 |
| **æ¥å…¥é—¨æ§›** | ä½ï¼ˆæ³¨å†Œå³ç”¨ï¼‰ | é«˜ï¼ˆéœ€è¦äº‘è´¦å·ï¼‰ |
| **ä»·æ ¼** | ä¸å®˜æ–¹ç›¸åŒ | é€šå¸¸ç•¥é«˜ |
| **ä¼ä¸šåˆè§„** | ä¸€èˆ¬ | å¼ºï¼ˆSLAã€æ•°æ®åˆè§„ï¼‰ |
| **é€‚åˆåœºæ™¯** | ä¸ªäººå¼€å‘è€…ã€åˆåˆ›å…¬å¸ | å¤§ä¼ä¸šã€åˆè§„è¦æ±‚é«˜çš„åœºæ™¯ |

### åŠ¨æ‰‹è¯•è¯•ï¼ˆPracticeï¼‰

æˆ‘ä»¬ç”¨ OpenRouter æ¥å®ç°"ä¸€å¥—ä»£ç è°ƒç”¨å¤šä¸ªæ¨¡å‹"å’Œ"æ¨¡å‹è‡ªåŠ¨é™çº§"ã€‚

**ç¬¬ 1 æ­¥ï¼šè·å– OpenRouter API Key**

1. å‰å¾€ [OpenRouter](https://openrouter.ai/) æ³¨å†Œ
2. åœ¨ [Keys](https://openrouter.ai/keys) é¡µé¢åˆ›å»º API Key
3. å……å€¼ï¼ˆæœ€ä½ $5ï¼Œæ”¯æŒä¿¡ç”¨å¡ï¼‰

**ç¬¬ 2 æ­¥ï¼šç”¨ OpenAI SDK è°ƒç”¨ OpenRouter**

```python
from openai import OpenAI

# OpenRouter å®Œå…¨å…¼å®¹ OpenAI API æ ¼å¼
client = OpenAI(
    api_key="YOUR_OPENROUTER_API_KEY",
    base_url="https://openrouter.ai/api/v1",
)

# è°ƒç”¨ GPT-4o-mini
response = client.chat.completions.create(
    model="openai/gpt-4.1-mini",  # æ ¼å¼ï¼šæä¾›å•†/æ¨¡å‹å
    messages=[{"role": "user", "content": "ç”¨ä¸€å¥è¯ä»‹ç» Python"}],
)
print("ã€GPT-4o-miniã€‘")
print(response.choices[0].message.content)

# è°ƒç”¨ Claude Sonnet
response = client.chat.completions.create(
    model="anthropic/claude-sonnet-4.6",
    messages=[{"role": "user", "content": "ç”¨ä¸€å¥è¯ä»‹ç» Python"}],
)
print("\nã€Claude Sonnetã€‘")
print(response.choices[0].message.content)

# è°ƒç”¨ DeepSeek-V3
response = client.chat.completions.create(
    model="deepseek/deepseek-chat",
    messages=[{"role": "user", "content": "ç”¨ä¸€å¥è¯ä»‹ç» Python"}],
)
print("\nã€DeepSeek-V3ã€‘")
print(response.choices[0].message.content)
```

**æ ¸å¿ƒè¦ç‚¹ï¼š**
- åªéœ€è¦æ”¹ `base_url` å’Œ `model` å‚æ•°ï¼Œä»£ç å…¶ä»–éƒ¨åˆ†å®Œå…¨ä¸å˜
- æ¨¡å‹åæ ¼å¼ï¼š`æä¾›å•†/æ¨¡å‹å`ï¼ˆå¦‚ `openai/gpt-4.1-mini`ã€`anthropic/claude-sonnet-4.6`ï¼‰

**ç¬¬ 3 æ­¥ï¼šè‡ªåŠ¨é™çº§ï¼ˆFallbackï¼‰**

```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_OPENROUTER_API_KEY",
    base_url="https://openrouter.ai/api/v1",
)

def chat_with_fallback(user_message):
    """
    ä¼˜å…ˆä½¿ç”¨é«˜è´¨é‡æ¨¡å‹ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨é™çº§åˆ°å¤‡é€‰æ¨¡å‹
    """
    models = [
        "openai/gpt-4o",           # ä¸»åŠ›ï¼šè´¨é‡æœ€é«˜ä½†æœ€è´µ
        "openai/gpt-4.1-mini",      # å¤‡é€‰ 1ï¼šæ€§ä»·æ¯”é«˜
        "google/gemini-2.0-flash", # å¤‡é€‰ 2ï¼šå…è´¹é¢åº¦å¤§
        "deepseek/deepseek-chat",  # å¤‡é€‰ 3ï¼šæœ€ä¾¿å®œ
    ]
    
    for model in models:
        try:
            print(f"å°è¯•è°ƒç”¨ï¼š{model}")
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": user_message}],
                timeout=10,  # 10 ç§’è¶…æ—¶
            )
            print(f"âœ… æˆåŠŸï¼ä½¿ç”¨æ¨¡å‹ï¼š{model}\n")
            return response.choices[0].message.content
        
        except Exception as e:
            print(f"âŒ å¤±è´¥ï¼š{e}\n")
            continue
    
    return "æ‰€æœ‰æ¨¡å‹å‡è°ƒç”¨å¤±è´¥"

# æµ‹è¯•
result = chat_with_fallback("ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯é€’å½’")
print("å›ç­”ï¼š", result)
```

**ç¬¬ 4 æ­¥ï¼šæ™ºèƒ½è·¯ç”±ï¼ˆè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹ï¼‰**

OpenRouter æ”¯æŒç”¨ `model` å‚æ•°æŒ‡å®šè·¯ç”±ç­–ç•¥ï¼š

```python
# è‡ªåŠ¨é€‰æ‹©æœ€ä¾¿å®œçš„æ¨¡å‹
response = client.chat.completions.create(
    model="openrouter/auto",  # è‡ªåŠ¨è·¯ç”±
    messages=[{"role": "user", "content": "ä½ å¥½"}],
    extra_body={
        "route": "cheapest",  # æŒ‰ä»·æ ¼é€‰ï¼ˆcheapest / fastest / bestï¼‰
    },
)
print("ä½¿ç”¨çš„æ¨¡å‹ï¼š", response.model)

# è‡ªåŠ¨é€‰æ‹©æœ€å¿«çš„æ¨¡å‹
response = client.chat.completions.create(
    model="openrouter/auto",
    messages=[{"role": "user", "content": "ä½ å¥½"}],
    extra_body={
        "route": "fastest",
    },
)
print("ä½¿ç”¨çš„æ¨¡å‹ï¼š", response.model)
```

**è¿›é˜¶æŠ€å·§ï¼šå¯¹æ¯”å¤šä¸ªæ¨¡å‹çš„å›ç­”**

```python
import asyncio
from openai import AsyncOpenAI

async def compare_models_async(question, models):
    """
    å¹¶å‘è°ƒç”¨å¤šä¸ªæ¨¡å‹ï¼Œå¯¹æ¯”å›ç­”
    """
    client = AsyncOpenAI(
        api_key="YOUR_OPENROUTER_API_KEY",
        base_url="https://openrouter.ai/api/v1",
    )
    
    async def call_model(model):
        response = await client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": question}],
        )
        return {
            "model": model,
            "answer": response.choices[0].message.content,
            "tokens": response.usage.total_tokens,
        }
    
    tasks = [call_model(model) for model in models]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    return results

# æµ‹è¯•ï¼šåŒæ—¶å¯¹æ¯” 5 ä¸ªæ¨¡å‹
models = [
    "openai/gpt-4.1-mini",
    "anthropic/claude-sonnet-4.6",
    "google/gemini-2.0-flash",
    "deepseek/deepseek-chat",
    "qwen/qwen-2.5-72b-instruct",
]

results = asyncio.run(compare_models_async(
    "ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯ Docker",
    models
))

for result in results:
    if isinstance(result, dict):
        print(f"\nã€{result['model']}ã€‘")
        print(result['answer'])
        print(f"Tokens: {result['tokens']}")
```

<ColabBadge path="demos/02-ai-landscape/openrouter_demo.ipynb" />

**ä½¿ç”¨ ZenMuxï¼ˆå›½å†…æ›¿ä»£æ–¹æ¡ˆï¼‰ï¼š**

ZenMux ä¸ OpenRouter ç±»ä¼¼ï¼Œä½†æ”¯æŒå›½å†…æ”¯ä»˜æ–¹å¼ï¼š

```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_ZENMUX_API_KEY",
    base_url="https://api.zenmux.com/v1",
)

response = client.chat.completions.create(
    model="gpt-4.1-mini",  # ZenMux çš„æ¨¡å‹åä¸éœ€è¦å‰ç¼€
    messages=[{"role": "user", "content": "ä½ å¥½"}],
)
print(response.choices[0].message.content)
```

### å°ç»“ï¼ˆReflectionï¼‰

- **è§£å†³äº†ä»€ä¹ˆ**ï¼šé€šè¿‡èšåˆå¹³å°ï¼Œç”¨ä¸€å¥—ä»£ç ï¼ˆOpenAI SDKï¼‰è°ƒç”¨æ‰€æœ‰æ¨¡å‹ï¼Œè½»æ¾å®ç°æ¨¡å‹åˆ‡æ¢å’Œé™çº§
- **æ²¡è§£å†³ä»€ä¹ˆ**ï¼šèšåˆå¹³å°è¿˜æ˜¯è¦è”ç½‘ã€è¦èŠ±é’±ã€‚å¦‚æœæƒ³é›¶æˆæœ¬ã€ç¦»çº¿è¿è¡Œæ€ä¹ˆåŠï¼Ÿä¸‹ä¸€èŠ‚ä»‹ç»æœ¬åœ°æ¨¡å‹éƒ¨ç½²
- **å…³é”®è¦ç‚¹**ï¼š
  1. **èšåˆå¹³å°è§£å†³ NÃ—M é—®é¢˜**ï¼šä» NÃ—M é™ä½åˆ° N+M å¤æ‚åº¦
  2. **OpenRouter æ¨è**ï¼šæ”¯æŒ 200+ æ¨¡å‹ã€ä»·æ ¼é€æ˜ã€è‡ªåŠ¨è·¯ç”±
  3. **äº‘å¹³å°é€‚åˆä¼ä¸š**ï¼šAzure / AWS / GCP æä¾› SLA å’Œåˆè§„ä¿éšœ
  4. **æ ¸å¿ƒæŠ€æœ¯**ï¼šç»Ÿä¸€æ¥å£ï¼ˆOpenAI SDKï¼‰+ è‡ªåŠ¨é™çº§ï¼ˆtry-exceptï¼‰

::: tip ä¸€å¥è¯æ€»ç»“
**èšåˆå¹³å° = AI è¶…å¸‚ï¼Œä¸€ä¸ªæ¥å£ä¹°éå…¨çƒæ¨¡å‹ï¼Œè¿˜èƒ½è‡ªåŠ¨æ¯”ä»·å’Œé™çº§ã€‚**
:::

---

*æœ€åæ›´æ–°ï¼š2026-02-20*
