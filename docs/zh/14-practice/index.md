# ç¬¬ 14 ç« ï¼šIT éƒ¨é—¨å®æˆ˜åœºæ™¯

> **ä»ç†è®ºåˆ°å®æˆ˜**ï¼šå­¦å®Œæœ¬ç« ï¼Œä½ èƒ½å®Œæˆè‡³å°‘ä¸€ä¸ªå¯éƒ¨ç½²åˆ°å›¢é˜Ÿçš„ AI åº”ç”¨é¡¹ç›®ï¼ˆä¸æ˜¯ç©å…·ï¼Œæ˜¯èƒ½ç”¨çš„é‚£ç§ï¼‰

å‰é¢ 13 ç« å­¦çš„éƒ½æ˜¯**æ­¦åŠŸæ‹›å¼**ï¼Œè¿™ä¸€ç« æ˜¯**å®æˆ˜å¯¹æ‰“**ã€‚æˆ‘ä»¬è¦åš 4 ä¸ªçœŸå®é¡¹ç›®ï¼š
1. **çŸ¥è¯†åº“ Q&A**ï¼šå…¬å¸çš„ç™¾ç§‘å…¨ä¹¦ï¼Œå‘Šåˆ«å¤§æµ·æé’ˆ
2. **Code Review åŠ©æ‰‹**ï¼šAI ä»£ç å®¡æŸ¥å®˜ï¼ŒæŒ‘æ¯›ç—…æ¯”äººè¿˜ç‹ 
3. **è¿ç»´æ™ºèƒ½åŠ©æ‰‹**ï¼šå‡Œæ™¨ 3 ç‚¹çš„æ•‘æ˜Ÿï¼Œæ—¥å¿—åˆ†æ+æ•…éšœè¯Šæ–­
4. **å›¢é˜Ÿå·¥å…·é“¾**ï¼šä»ä¸ªäººåˆ°å›¢é˜Ÿï¼Œè®© AI è½åœ°ä¸ç¿»è½¦

::: tip ç›®æ ‡
**æœ¬ç« ç»“æŸåï¼Œä½ èƒ½æ‹¿ç€è¿™ 4 ä¸ªé¡¹ç›®å»å’Œè€æ¿è°ˆåŠ è–ªã€‚**
:::


```mermaid
graph LR
    A["æŠ€èƒ½å‡†å¤‡å®Œæˆ"] -->|åº”ç”¨| B["çŸ¥è¯†åº“ Q&A<br/>RAG ç³»ç»Ÿ"]
    B -->|è¿›é˜¶| C["ä»£ç å®¡æŸ¥<br/>AI Assistant"]
    C -->|å¤æ‚åœºæ™¯| D["è¿ç»´åŠ©æ‰‹<br/>Multi-Agent"]
    D -->|å›¢é˜Ÿæ¨å¹¿| E["å·¥å…·é“¾æ­å»º<br/>å›¢é˜Ÿèµ‹èƒ½"]
    
    style A fill:#e1f5fe
    style B fill:#fff3e0
    style C fill:#fff3e0
    style D fill:#fff3e0
    style E fill:#c8e6c9
```

**ç« èŠ‚å¯¼è§ˆï¼š**

- **14.1 å†…éƒ¨çŸ¥è¯†åº“ Q&A ç³»ç»Ÿ**ï¼šå®Œæ•´çš„æ–‡æ¡£é—®ç­”ç³»ç»Ÿï¼ˆRAG + å¼•ç”¨æº¯æºï¼‰
- **14.2 AI Code Review åŠ©æ‰‹**ï¼šè‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥å·¥å…·
- **14.3 IT è¿ç»´æ™ºèƒ½åŠ©æ‰‹**ï¼šæ—¥å¿—åˆ†æ + æ•…éšœè¯Šæ–­ Multi-Agent ç³»ç»Ÿ
- **14.4 å›¢é˜Ÿ AI å·¥å…·é“¾æ­å»º**ï¼šä»ä¸ªäººåˆ°å›¢é˜Ÿçš„ AI è½åœ°æŒ‡å—

---

::: tip è¿è¡Œç¯å¢ƒ
æœ¬ç« å®æˆ˜é¡¹ç›®éœ€è¦ä»¥ä¸‹ä¾èµ–ï¼š
```bash
pip install openai chromadb python-dotenv
```
éƒ¨åˆ†é¡¹ç›®è¿˜éœ€è¦ï¼š
```bash
pip install rank_bm25 flask  # æ··åˆæ£€ç´¢ã€Web æœåŠ¡
```
:::

## 14.1 å†…éƒ¨çŸ¥è¯†åº“ Q&A ç³»ç»Ÿï¼šå…¬å¸çš„ç™¾ç§‘å…¨ä¹¦ <DifficultyBadge level="intermediate" /> <CostBadge cost="$0.10" />

> ç»¼åˆåº”ç”¨ï¼šCh4ï¼ˆPromptï¼‰ã€Ch7ï¼ˆFunction Callingï¼‰ã€Ch12ï¼ˆRAGï¼‰ã€Ch13ï¼ˆç”Ÿäº§åŒ–ï¼‰

::: warning æ¯ä¸ªå…¬å¸éƒ½æœ‰çš„ç—›ç‚¹
**æ–°å‘˜å·¥**ï¼š"è¯·é—® Nginx SSL æ€ä¹ˆé…ç½®ï¼Ÿ"  
**è€å‘˜å·¥**ï¼š"å» Wiki æ‰¾æ‰¾"  
**æ–°å‘˜å·¥**ï¼šï¼ˆ30 åˆ†é’Ÿåï¼‰"æˆ‘æ‰¾äº† 5 ä¸ªæ–‡æ¡£ï¼Œå“ªä¸ªæ˜¯å¯¹çš„ï¼Ÿ"  
**è€å‘˜å·¥**ï¼šï¼ˆå¹æ°”ï¼‰"ç®—äº†æˆ‘ç»™ä½ å‘ä¸ªé“¾æ¥â€¦â€¦"
:::

### ä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿï¼ˆProblemï¼‰

**"å…¬å¸æœ‰å‡ ç™¾ä»½æŠ€æœ¯æ–‡æ¡£ï¼Œä½†æ¯æ¬¡æ‰¾ä¿¡æ¯éƒ½åƒå¤§æµ·æé’ˆã€‚"**

IT éƒ¨é—¨çš„ç—›ç‚¹ï¼š

| åœºæ™¯ | ç—›ç‚¹ | åæœ |
|------|------|------|
| **æ–°å‘˜å·¥å…¥èŒ** | ä¸çŸ¥é“å»å“ªæ‰¾æ–‡æ¡£ | åå¤é—®è€å‘˜å·¥ç›¸åŒé—®é¢˜ |
| **æŠ€æœ¯è§„èŒƒæŸ¥è¯¢** | æ–‡æ¡£åˆ†æ•£åœ¨å¤šä¸ªå¹³å° | èŠ± 30 åˆ†é’Ÿæ‰¾ä¸€ä¸ª API è¯´æ˜ |
| **å†å²å†³ç­–æŸ¥è¯¢** | é¡¹ç›®æ–‡æ¡£æ— äººç»´æŠ¤ | é‡å¤çŠ¯ç›¸åŒé”™è¯¯ |
| **è·¨éƒ¨é—¨åä½œ** | ä¸äº†è§£å…¶ä»–å›¢é˜Ÿçš„ç³»ç»Ÿ | é‡å¤é€ è½®å­ |

**ä¼ ç»Ÿè§£å†³æ–¹æ¡ˆçš„é—®é¢˜ï¼š**

- **å…¨æ–‡æœç´¢**ï¼šå…³é”®è¯åŒ¹é…ï¼Œæ— æ³•ç†è§£è¯­ä¹‰
- **Wiki ç³»ç»Ÿ**ï¼šéœ€è¦ç²¾ç¡®çŸ¥é“æ–‡æ¡£æ ‡é¢˜
- **äººå·¥å’¨è¯¢**ï¼šå ç”¨ä¸“å®¶æ—¶é—´ï¼Œæ•ˆç‡ä½

**éœ€è¦ï¼šæ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œèƒ½ç†è§£è‡ªç„¶è¯­è¨€é—®é¢˜ï¼Œå‡†ç¡®æ‰¾åˆ°ç­”æ¡ˆå¹¶ç»™å‡ºå‡ºå¤„ã€‚**

### å®ƒæ˜¯ä»€ä¹ˆï¼Ÿï¼ˆConceptï¼‰

**çŸ¥è¯†åº“ Q&A ç³»ç»Ÿ** æ˜¯åŸºäº RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰çš„æ–‡æ¡£é—®ç­”åº”ç”¨ï¼š

```mermaid
graph TD
    A["ç”¨æˆ·æé—®<br/>'å¦‚ä½•é…ç½® Nginx SSL'"] --> B["Query æ”¹å†™<br/>æå–å…³é”®è¯"]
    B --> C["å‘é‡æ£€ç´¢<br/>Top-K ç›¸å…³æ–‡æ¡£"]
    C --> D["é‡æ’åº<br/>ç²¾å‡†åº¦æ’åº"]
    D --> E["æ„å»º Prompt<br/>é—®é¢˜+æ–‡æ¡£ç‰‡æ®µ"]
    E --> F["LLM ç”Ÿæˆç­”æ¡ˆ<br/>+å¼•ç”¨æ¥æº"]
    F --> G["è¿”å›ç­”æ¡ˆ<br/>[æ¥æº: nginx.md#L45]"]
    
    H["æ–‡æ¡£åº“<br/>PDF/Markdown/Excel"] --> I["è§£æ&åˆ‡å—<br/>Chunking"]
    I --> J["Embedding<br/>å‘é‡åŒ–"]
    J --> K["å‘é‡æ•°æ®åº“<br/>Chroma/Qdrant"]
    K --> C
    
    style A fill:#e1f5fe
    style F fill:#c8e6c9
    style K fill:#fff3e0
```

**æ ¸å¿ƒæ¶æ„ï¼š**

### 1. æ–‡æ¡£å¤„ç†æµç¨‹

```python
# ä¼ªä»£ç 
documents = load_documents(["*.pdf", "*.md", "*.xlsx"])
chunks = split_documents(documents, chunk_size=500, overlap=50)
embeddings = embed_chunks(chunks)
vector_db.store(embeddings)
```

**åˆ‡å—ç­–ç•¥ï¼š**

| æ–‡æ¡£ç±»å‹ | åˆ‡å—å¤§å° | ç­–ç•¥ |
|---------|---------|------|
| **Markdown** | 500 Token | æŒ‰æ ‡é¢˜å±‚çº§åˆ‡åˆ† |
| **PDF** | 400 Token | æŒ‰æ®µè½åˆ‡åˆ† |
| **ä»£ç ** | å‡½æ•°çº§åˆ« | æŒ‰å‡½æ•°/ç±»åˆ‡åˆ† |
| **Excel** | è¡Œ/è¡¨ | æŒ‰è¡¨æ ¼ç»“æ„åˆ‡åˆ† |

### 2. æ£€ç´¢æµç¨‹

```python
# ç”¨æˆ·æé—®
question = "å¦‚ä½•é…ç½® Nginx SSLï¼Ÿ"

# å‘é‡æ£€ç´¢ï¼ˆTop-5ï¼‰
relevant_chunks = vector_db.search(question, top_k=5)

# é‡æ’åºï¼ˆå¯é€‰ï¼Œæé«˜ç²¾å‡†åº¦ï¼‰
reranked_chunks = reranker.rerank(question, relevant_chunks)[:3]

# æ„å»º Prompt
prompt = build_rag_prompt(question, reranked_chunks)

# ç”Ÿæˆç­”æ¡ˆ
answer = llm.generate(prompt)
```

**å…³é”®æŠ€æœ¯ç‚¹ï¼š**

| æŠ€æœ¯ | ä½œç”¨ | å·¥å…· |
|------|------|------|
| **Embedding æ¨¡å‹** | å°†æ–‡æœ¬è½¬ä¸ºå‘é‡ | OpenAI text-embedding-3, BGE |
| **å‘é‡æ•°æ®åº“** | å­˜å‚¨å’Œæ£€ç´¢å‘é‡ | Chroma, Qdrant, Pinecone |
| **é‡æ’åº** | ç²¾å‡†æ’åºç›¸å…³æ–‡æ¡£ | Cohere Rerank, BGE Reranker |
| **å¼•ç”¨æº¯æº** | æ ‡æ³¨ç­”æ¡ˆæ¥æº | è‡ªå®šä¹‰ Prompt |
| **æ··åˆæ£€ç´¢** | å‘é‡ + å…³é”®è¯ | BM25 + Vector |

### 3. Prompt è®¾è®¡

```python
RAG_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†åº“é—®ç­”åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£ç‰‡æ®µå›ç­”ç”¨æˆ·é—®é¢˜ã€‚

é‡è¦è§„åˆ™ï¼š
1. åªä½¿ç”¨æä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç­”æ¡ˆï¼Œæ˜ç¡®è¯´"æ–‡æ¡£ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
3. åœ¨ç­”æ¡ˆæœ«å°¾åˆ—å‡ºå¼•ç”¨æ¥æºï¼ˆæ ¼å¼ï¼š[æ¥æº: æ–‡ä»¶å#è¡Œå·]ï¼‰
4. å¦‚æœå¤šä¸ªæ–‡æ¡£æåˆ°ç›¸åŒä¿¡æ¯ï¼Œåˆ—å‡ºæ‰€æœ‰æ¥æº

æ–‡æ¡£ç‰‡æ®µï¼š
{documents}

ç”¨æˆ·é—®é¢˜ï¼š{question}

å›ç­”ï¼š
"""
```

### åŠ¨æ‰‹è¯•è¯•ï¼ˆPracticeï¼‰

**å®Œæ•´å®ç°ï¼šå†…éƒ¨çŸ¥è¯†åº“ Q&A ç³»ç»Ÿ**

```python
from openai import OpenAI
import chromadb
from pathlib import Path
import hashlib

client = OpenAI()

class KnowledgeBase:
    """çŸ¥è¯†åº“ Q&A ç³»ç»Ÿ"""
    
    def __init__(self, collection_name: str = "company_docs"):
        self.client = OpenAI()
        self.chroma_client = chromadb.Client()
        self.collection = self.chroma_client.get_or_create_collection(collection_name)
    
    def add_document(self, content: str, source: str, metadata: dict = None):
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        # åˆ‡å—ï¼ˆç®€åŒ–ç‰ˆï¼šæŒ‰æ®µè½åˆ‡åˆ†ï¼‰
        chunks = self._split_into_chunks(content, chunk_size=500)
        
        for i, chunk in enumerate(chunks):
            # ç”Ÿæˆ Embedding
            embedding = self._embed(chunk)
            
            # ç”Ÿæˆå”¯ä¸€ ID
            chunk_id = hashlib.md5(f"{source}_{i}".encode()).hexdigest()
            
            # å­˜å‚¨
            self.collection.add(
                ids=[chunk_id],
                embeddings=[embedding],
                documents=[chunk],
                metadatas=[{
                    "source": source,
                    "chunk_index": i,
                    **(metadata or {})
                }]
            )
        
        print(f"âœ“ å·²æ·»åŠ æ–‡æ¡£: {source} ({len(chunks)} ä¸ªç‰‡æ®µ)")
    
    def _split_into_chunks(self, text: str, chunk_size: int) -> list[str]:
        """ç®€å•çš„æ–‡æœ¬åˆ‡å—ï¼ˆæŒ‰å­—æ•°ï¼‰"""
        words = text.split()
        chunks = []
        
        for i in range(0, len(words), chunk_size):
            chunk = " ".join(words[i:i + chunk_size])
            chunks.append(chunk)
        
        return chunks
    
    def _embed(self, text: str) -> list[float]:
        """ç”Ÿæˆ Embedding"""
        response = self.client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding
    
    def search(self, question: str, top_k: int = 3) -> list[dict]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        # æŸ¥è¯¢å‘é‡
        query_embedding = self._embed(question)
        
        # å‘é‡æ£€ç´¢
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )
        
        # æ ¼å¼åŒ–ç»“æœ
        retrieved_docs = []
        for i in range(len(results['ids'][0])):
            retrieved_docs.append({
                "content": results['documents'][0][i],
                "source": results['metadatas'][0][i]['source'],
                "chunk_index": results['metadatas'][0][i]['chunk_index'],
                "distance": results['distances'][0][i]
            })
        
        return retrieved_docs
    
    def ask(self, question: str) -> dict:
        """é—®ç­”æ¥å£"""
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        docs = self.search(question, top_k=3)
        
        if not docs:
            return {
                "answer": "æŠ±æ­‰ï¼ŒçŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚",
                "sources": []
            }
        
        # 2. æ„å»º Prompt
        docs_text = "\n\n".join([
            f"[æ–‡æ¡£ {i+1}] æ¥æº: {doc['source']}\n{doc['content']}"
            for i, doc in enumerate(docs)
        ])
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†åº“é—®ç­”åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£ç‰‡æ®µå›ç­”ç”¨æˆ·é—®é¢˜ã€‚

é‡è¦è§„åˆ™ï¼š
1. åªä½¿ç”¨æä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç­”æ¡ˆï¼Œæ˜ç¡®è¯´"æ–‡æ¡£ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
3. åœ¨ç­”æ¡ˆæœ«å°¾åˆ—å‡ºå¼•ç”¨æ¥æºï¼ˆæ ¼å¼ï¼š[æ¥æº: æ–‡ä»¶å]ï¼‰

æ–‡æ¡£ç‰‡æ®µï¼š
{docs_text}

ç”¨æˆ·é—®é¢˜ï¼š{question}

å›ç­”ï¼š
"""
        
        # 3. è°ƒç”¨ LLM
        response = self.client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3  # é™ä½éšæœºæ€§,æé«˜å‡†ç¡®æ€§
        )
        
        answer = response.choices[0].message.content
        
        return {
            "answer": answer,
            "sources": [{"source": doc['source'], "snippet": doc['content'][:100]} for doc in docs]
        }

# ===== ä½¿ç”¨ç¤ºä¾‹ =====

# 1. åˆ›å»ºçŸ¥è¯†åº“
kb = KnowledgeBase()

# 2. æ·»åŠ æ–‡æ¡£ï¼ˆæ¨¡æ‹Ÿå…¬å¸æŠ€æœ¯æ–‡æ¡£ï¼‰
kb.add_document(
    content="""
Nginx SSL é…ç½®æŒ‡å—

1. ç”Ÿæˆ SSL è¯ä¹¦
ä½¿ç”¨ Let's Encrypt ç”Ÿæˆå…è´¹è¯ä¹¦ï¼š
sudo certbot --nginx -d yourdomain.com

2. é…ç½® Nginx
ç¼–è¾‘ /etc/nginx/sites-available/defaultï¼š

server {
    listen 443 ssl;
    server_name yourdomain.com;
    
    ssl_certificate /etc/letsencrypt/live/yourdomain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/yourdomain.com/privkey.pem;
    
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;
}

3. é‡å¯ Nginx
sudo systemctl restart nginx

æ³¨æ„ï¼šç¡®ä¿é˜²ç«å¢™å¼€æ”¾ 443 ç«¯å£ã€‚
""",
    source="nginx-ssl.md",
    metadata={"category": "è¿ç»´", "author": "å¼ ä¸‰"}
)

kb.add_document(
    content="""
Python FastAPI éƒ¨ç½²æŒ‡å—

1. å®‰è£…ä¾èµ–
pip install fastapi uvicorn

2. åˆ›å»ºåº”ç”¨
# main.py
from fastapi import FastAPI

app = FastAPI()

@app.get("/")
def read_root():
    return {"message": "Hello World"}

3. è¿è¡ŒæœåŠ¡
uvicorn main:app --host 0.0.0.0 --port 8000

4. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
ä½¿ç”¨ Gunicorn + Uvicornï¼š
gunicorn main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker

æ¨èä½¿ç”¨ Supervisor ç®¡ç†è¿›ç¨‹ã€‚
""",
    source="fastapi-deployment.md",
    metadata={"category": "åç«¯", "author": "æå››"}
)

kb.add_document(
    content="""
å…¬å¸ API ç½‘å…³ä½¿ç”¨è§„èŒƒ

1. è®¤è¯æ–¹å¼
æ‰€æœ‰ API è¯·æ±‚å¿…é¡»åŒ…å« Authorization headerï¼š
Authorization: Bearer <your_token>

2. é™æµè§„åˆ™
- æ™®é€šç”¨æˆ·ï¼š100 req/min
- VIP ç”¨æˆ·ï¼š1000 req/min
- è¶…é™è¿”å› 429 çŠ¶æ€ç 

3. å¸¸è§é”™è¯¯ç 
- 401: æœªæˆæƒï¼ŒToken æ— æ•ˆ
- 403: ç¦æ­¢è®¿é—®ï¼Œæƒé™ä¸è¶³
- 429: è¯·æ±‚è¿‡å¤šï¼Œè§¦å‘é™æµ
- 500: æœåŠ¡å™¨é”™è¯¯

4. è”ç³»æ–¹å¼
é‡åˆ°é—®é¢˜è”ç³»ï¼šapi-support@company.com
""",
    source="api-gateway.md",
    metadata={"category": "è§„èŒƒ", "author": "ç‹äº”"}
)

# 3. æµ‹è¯•é—®ç­”
print("="*60)
print("çŸ¥è¯†åº“ Q&A ç³»ç»Ÿæµ‹è¯•")
print("="*60)

questions = [
    "å¦‚ä½•é…ç½® Nginx çš„ SSLï¼Ÿ",
    "FastAPI æ€ä¹ˆéƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒï¼Ÿ",
    "API é™æµæ˜¯å¤šå°‘ï¼Ÿ",
    "å¦‚ä½•è¿æ¥æ•°æ®åº“ï¼Ÿ",  # çŸ¥è¯†åº“ä¸­æ²¡æœ‰çš„é—®é¢˜
]

for q in questions:
    print(f"\né—®é¢˜ï¼š{q}")
    print("-"*60)
    
    result = kb.ask(q)
    
    print(f"å›ç­”ï¼š{result['answer']}")
    print(f"\nå¼•ç”¨æ¥æºï¼š")
    for source in result['sources']:
        print(f"  - {source['source']}: {source['snippet']}...")
```

**å¢å¼ºåŠŸèƒ½ï¼šæ··åˆæ£€ç´¢**

```python
from rank_bm25 import BM25Okapi

class HybridKnowledgeBase(KnowledgeBase):
    """æ··åˆæ£€ç´¢ï¼šå‘é‡æ£€ç´¢ + BM25 å…³é”®è¯æ£€ç´¢"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.bm25_corpus = []
        self.bm25_metadata = []
        self.bm25_index = None
    
    def add_document(self, content: str, source: str, metadata: dict = None):
        """æ·»åŠ æ–‡æ¡£ï¼ˆåŒæ—¶å»ºç«‹ BM25 ç´¢å¼•ï¼‰"""
        super().add_document(content, source, metadata)
        
        # æ·»åŠ åˆ° BM25 ç´¢å¼•
        chunks = self._split_into_chunks(content, chunk_size=500)
        for i, chunk in enumerate(chunks):
            self.bm25_corpus.append(chunk.split())
            self.bm25_metadata.append({"source": source, "chunk_index": i, "content": chunk})
        
        # é‡å»º BM25 ç´¢å¼•
        self.bm25_index = BM25Okapi(self.bm25_corpus)
    
    def search(self, question: str, top_k: int = 3) -> list[dict]:
        """æ··åˆæ£€ç´¢ï¼šå‘é‡ + BM25"""
        # 1. å‘é‡æ£€ç´¢
        vector_results = super().search(question, top_k=top_k * 2)
        
        # 2. BM25 æ£€ç´¢
        bm25_scores = self.bm25_index.get_scores(question.split())
        top_bm25_indices = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:top_k * 2]
        
        bm25_results = [
            {
                "content": self.bm25_metadata[i]["content"],
                "source": self.bm25_metadata[i]["source"],
                "chunk_index": self.bm25_metadata[i]["chunk_index"],
                "score": bm25_scores[i]
            }
            for i in top_bm25_indices
        ]
        
        # 3. åˆå¹¶ç»“æœï¼ˆç®€å•ç­–ç•¥ï¼šå–å¹¶é›†åæŒ‰åˆ†æ•°æ’åºï¼‰
        combined = {}
        
        for doc in vector_results:
            key = f"{doc['source']}_{doc['chunk_index']}"
            combined[key] = doc
        
        for doc in bm25_results:
            key = f"{doc['source']}_{doc['chunk_index']}"
            if key not in combined:
                combined[key] = doc
        
        # è¿”å› Top-K
        return list(combined.values())[:top_k]
```

<ColabBadge path="demos/14-practice/knowledge_base.ipynb" />

### å°ç»“ï¼ˆReflectionï¼‰

**ğŸ¯ ä¸€å¥è¯æ€»ç»“ï¼šçŸ¥è¯†åº“ Q&A æ˜¯å…¬å¸çš„ç™¾ç§‘å…¨ä¹¦ï¼ŒRAG è®©æ–‡æ¡£"æ´»"èµ·æ¥ï¼Œå¼•ç”¨æº¯æºè®©ç­”æ¡ˆæœ‰æ®å¯æŸ¥ã€‚**

- **è§£å†³äº†ä»€ä¹ˆ**ï¼šæ„å»ºå®Œæ•´çš„çŸ¥è¯†åº“ Q&A ç³»ç»Ÿï¼Œæ”¯æŒæ–‡æ¡£ä¸Šä¼ ã€å‘é‡æ£€ç´¢ã€å¼•ç”¨æº¯æº
- **æ²¡è§£å†³ä»€ä¹ˆ**ï¼šæ–‡æ¡£ Q&A æå®šäº†ï¼Œä½†æ€ä¹ˆè‡ªåŠ¨åŒ–ä»£ç å®¡æŸ¥ï¼Ÿâ€”â€”ä¸‹ä¸€èŠ‚ä»‹ç» AI Code Review åŠ©æ‰‹
- **å…³é”®è¦ç‚¹**ï¼š
  1. **RAG æ˜¯æ ¸å¿ƒæ¶æ„**ï¼šæ£€ç´¢ + ç”Ÿæˆï¼Œé¿å…æ¨¡å‹èƒ¡ç¼–ä¹±é€ 
  2. **Embedding + å‘é‡æ•°æ®åº“**ï¼šè¯­ä¹‰æ£€ç´¢æ¯”å…³é”®è¯æœç´¢æ›´æ™ºèƒ½ï¼ˆèƒ½ç†è§£"SSL é…ç½®"å’Œ"HTTPS è®¾ç½®"æ˜¯ä¸€å›äº‹ï¼‰
  3. **å¼•ç”¨æº¯æºå¾ˆé‡è¦**ï¼šè®©ç”¨æˆ·çŸ¥é“ç­”æ¡ˆæ¥æºï¼Œå»ºç«‹ä¿¡ä»»ï¼ˆä¸ç„¶å°±æ˜¯"æ®æˆ‘æ‰€çŸ¥"ï¼‰
  4. **æ··åˆæ£€ç´¢æå‡å‡†ç¡®ç‡**ï¼šå‘é‡æ£€ç´¢ + BM25 å…³é”®è¯æ£€ç´¢ï¼ˆä¸¤æ¡è…¿èµ°è·¯æ›´ç¨³ï¼‰
  5. **Prompt è®¾è®¡å…³é”®**ï¼šæ˜ç¡®å‘Šè¯‰æ¨¡å‹"ä¸è¦ç¼–é€ "ï¼ˆä¸ç„¶å®ƒä¼šçè¯´ï¼‰

::: tip è®°ä½è¿™ä¸ªæ¯”å–»
çŸ¥è¯†åº“ Q&A = å…¬å¸çš„ç™¾ç§‘å…¨ä¹¦ï¼šæƒ³çŸ¥é“ä»€ä¹ˆï¼Œé—®å®ƒå°±è¡Œï¼Œè¿˜é™„å¸¦é¡µç å¼•ç”¨ã€‚
:::

---

*æœ€åæ›´æ–°ï¼š2026-02-20*
